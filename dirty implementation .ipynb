{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/abhiksark/MajorProject/blob/master/dirty%20implementation%20.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "B4zt5FHN23xS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-l1zVwj2rvh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "frtvbwuj26gY",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "598151f6-86e2-4fb3-d2b0-fee85e4cbe2f"
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!pip install -U -q PyDrive ## you will have install for every colab session\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-66ef2110-b3d7-4b20-959d-2b5fbb38c055\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-66ef2110-b3d7-4b20-959d-2b5fbb38c055\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jw4njDja3IJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0a885a01-5195-4e6d-ab4d-eb57c0a10061"
      },
      "cell_type": "code",
      "source": [
        "!mkdir /content/.kaggle\n",
        "#!mv /content/.kaggle kaggle.json\n",
        "#!ls\n",
        "#!chmod 600 ~ kaggle.json\n",
        "!mv kaggle.json /content/.kaggle\n",
        "!ls /content/.kaggle/\n",
        "!chmod 600 ~ /content/.kaggle/kaggle.json\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/.kaggle’: File exists\n",
            "mv: cannot stat 'kaggle.json': No such file or directory\n",
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UfRtQLQg3Ova",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "e0e209c9-ded2-493f-bf95-0178402e91f5"
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!kaggle competitions list -s health\n",
        "!kaggle competitions download -c diabetic-retinopathy-detection -p datalab"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.3.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.4.16)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "ref                                        deadline             category      reward  teamCount  userHasEntered  \n",
            "-----------------------------------------  -------------------  --------  ----------  ---------  --------------  \n",
            "hhp                                        2013-04-04 07:00:00  Featured    $500,000       1353           False  \n",
            "ultrasound-nerve-segmentation              2016-08-18 23:59:00  Featured    $100,000        923           False  \n",
            "diabetic-retinopathy-detection             2015-07-27 23:59:00  Featured    $100,000        661            True  \n",
            "msk-redefining-cancer-treatment            2017-10-02 23:59:00  Research     $15,000       1386           False  \n",
            "second-annual-data-science-bowl            2016-03-14 23:59:00  Featured    $200,000        773           False  \n",
            "melbourne-university-seizure-prediction    2016-12-01 23:59:00  Research     $20,000        478           False  \n",
            "data-science-bowl-2017                     2017-04-12 23:59:00  Featured  $1,000,000       1972            True  \n",
            "intel-mobileodt-cervical-cancer-screening  2017-06-21 23:59:00  Featured    $100,000        848           False  \n",
            "mens-machine-learning-competition-2018     2018-04-02 23:59:00  Featured     $50,000        934           False  \n",
            "march-machine-learning-mania-2014          2014-04-08 23:59:00  Featured     $15,000        248           False  \n",
            "trainLabels.csv.zip: Downloaded 69KB of 69KB\n",
            "sampleSubmission.csv.zip: Downloaded 82KB of 82KB\n",
            "sample.zip: Downloaded 10MB of 10MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train.zip.004: Downloaded 8GB of 8GB\n",
            "train.zip.002: Downloaded 8GB of 8GB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train.zip.001: Downloaded 8GB of 8GB\n",
            "train.zip.005: Downloaded 1GB of 1GB\n",
            "train.zip.003: Downloaded 8GB of 8GB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "test.zip.004: Downloaded 8GB of 8GB\n",
            "test.zip.005: Downloaded 8GB of 8GB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "test.zip.002: Downloaded 8GB of 8GB\n",
            "test.zip.003: Downloaded 8GB of 8GB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "test.zip.001: Downloaded 8GB of 8GB\n",
            "test.zip.006: Downloaded 8GB of 8GB\n",
            "test.zip.007: Downloaded 3GB of 3GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jj6uamgt5TCV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e5fd8e2d-dd1b-47e8-f767-6ea4f423462c"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install p7zip-full"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dDQvtK0V6ux2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!7z x datalab/train.zip.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DQ3jxusI3b1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "5bc25b97-90df-4ead-851d-507c79db7c84"
      },
      "cell_type": "code",
      "source": [
        "!ls train | head -4"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10003_left.jpeg\r\n",
            "10003_right.jpeg\r\n",
            "10007_left.jpeg\r\n",
            "10007_right.jpeg\r\n",
            "ls: write error: Broken pipe\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GWUUoSek9ONA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c6867077-65b9-4693-c4e9-df6230ec251e"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"from google.colab import files\n",
        "for i in range(11,59):\n",
        "  try:\n",
        "    files.download(\"train/100\"+str(int(i))+\"_left.jpeg\")\n",
        "    files.download(\"train/100\"+str(int(i))+\"_right.jpeg\")\n",
        "  except:\n",
        "     pass\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from google.colab import files\\nfor i in range(11,59):\\n  try:\\n    files.download(\"train/100\"+str(int(i))+\"_left.jpeg\")\\n    files.download(\"train/100\"+str(int(i))+\"_right.jpeg\")\\n  except:\\n     pass'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "yKyOlCzw3fdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd \n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h3PBKsUK32lI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "02152b38-447b-463d-ffd4-eeed1771491c"
      },
      "cell_type": "code",
      "source": [
        "!unzip datalab/trainLabels.csv.zip"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  datalab/trainLabels.csv.zip\r\n",
            "  inflating: trainLabels.csv         \r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E73RAbDG4QJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "2383297b-55ac-4633-8fda-aa0155b4d6d0"
      },
      "cell_type": "code",
      "source": [
        "trainLabels = pd.read_csv(\"trainLabels.csv\")\n",
        "trainLabels.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10_left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10_right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13_left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13_right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15_left</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      image  level\n",
              "0   10_left      0\n",
              "1  10_right      0\n",
              "2   13_left      0\n",
              "3  13_right      0\n",
              "4   15_left      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "mBhQmes-4ljy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "7b9d9df5-5242-471d-885f-3f892bd5c6bd"
      },
      "cell_type": "code",
      "source": [
        "trainLabels[\"level\"].hist()\n",
        "trainLabels[\"level\"].unique()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFKCAYAAAA0WNeQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIAx/wdxaXMQE56Y8gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0335ade4a8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vrLNneUYDbZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f9bdc82-1bee-4c10-bc8c-2870e5bf8a58"
      },
      "cell_type": "code",
      "source": [
        "listing = os.listdir(\"train\") \n",
        "len(listing)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35126"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "kqK0gjEtCnAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "listing_test=listing[:5000]\n",
        "listing_val=listing[5000:7000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rX-z7XDhCzb8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Apr 19 23:09:09 2018\n",
        "\n",
        "@author: abhik\n",
        "\"\"\"\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Standard resolution of images after processing.\n",
        "STD_RES = 756\n",
        "\n",
        "# Thresholding parameter.\n",
        "THRESH = 30  # For edge detection\n",
        "\n",
        "# Canny edge detection parameters.\n",
        "LOW_THRESH = 0\n",
        "MAX_THRESH = 255\n",
        "KERNEL = 3\n",
        "\n",
        "# Hough Circle Transform parameters.\n",
        "DP = 2  # Inverse accumulator ratio.\n",
        "MD = STD_RES  # Minimum distance between circles.\n",
        "P1 = 140\n",
        "P2 = 30\n",
        "MIN_R = int(STD_RES * 0.4)\n",
        "MAX_R = STD_RES\n",
        "\n",
        "# Blob detection parameters (for notch detection).\n",
        "BLOB_PARAMS = cv.SimpleBlobDetector_Params()\n",
        "BLOB_PARAMS.minThreshold = 0.0\n",
        "BLOB_PARAMS.maxThreshold = THRESH\n",
        "BLOB_PARAMS.thresholdStep = THRESH / 2\n",
        "BLOB_PARAMS.filterByArea = False\n",
        "BLOB_PARAMS.filterByColor = False\n",
        "BLOB_PARAMS.filterByConvexity = False\n",
        "BLOB_PARAMS.filterByInertia = True\n",
        "BLOB_PARAMS.minInertiaRatio = 0.05\n",
        "BLOB_PARAMS.maxInertiaRatio = 1\n",
        "\n",
        "\n",
        "def preprocess_image(path):\n",
        "    \"\"\"\n",
        "    Loads an image, converts to grayscale, flips the image if necessary based\n",
        "    on which eye it is and if there is a notch present, and equalizes the\n",
        "    image's histogram.\n",
        "    :param str path: Path to an image.\n",
        "    :rtype: numpy.ndarray\n",
        "    \"\"\"\n",
        "    # Loading the image also converts it to grayscale.\n",
        "    img = load_image(path)\n",
        "    img_thresh = threshold(img)\n",
        "\n",
        "    # Two-part notch-detection. Notch could be in upper-right quadrant, or it\n",
        "    # could be in the bottom-right quadrant. Try the upper-right corner first -\n",
        "    # if it's not there, try the bottom-right. If still no notch is detected,\n",
        "    # assume there is no notch present and do no inversion.\n",
        "    if detect_notch(img, img_thresh):\n",
        "        cv.flip(img, -1, img)\n",
        "        print(\"Notch detected in image {}.\".format(path.split('/')[-1]))\n",
        "    else:\n",
        "        vert_flip = cv.flip(img, 0)\n",
        "        vert_flip_thresh = cv.flip(img_thresh, 0)\n",
        "\n",
        "        if detect_notch(vert_flip, vert_flip_thresh):\n",
        "            cv.flip(img, -1, img)\n",
        "            print(\"Notch detected in image {}.\".format(path.split('/')[-1]))\n",
        "\n",
        "    # Examine the file name and flip the eye horizontally if it's a left eye.\n",
        "    if \"left\" in path:\n",
        "        cv.flip(img, 1, img)\n",
        "\n",
        "    # Finally, equalize the image.\n",
        "    cv.equalizeHist(img, img)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def load_image(path, grayscale=True, equalize=False, resize=True):\n",
        "    \"\"\"\n",
        "    Loads an image, transforms it to grayscale, and resizes it. Optionally\n",
        "    equalizes the image's histogram. Equalization seems to play poorly with\n",
        "    preprocessing however, so by default it is turned off.\n",
        "    :param path: Path to the image file.\n",
        "    :param grayscale: Flag for converting image to grayscale.\n",
        "    :param equalize: Flag for equalizing the image's histogram.\n",
        "    :param resize: Flag for resizing the image to standard resolution.\n",
        "    :rtype: np.ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    img_in = cv.imread(path, cv.IMREAD_GRAYSCALE if grayscale else -1)\n",
        "    if equalize:\n",
        "        cv.equalizeHist(img_in, img_in)\n",
        "\n",
        "    if resize:\n",
        "        img_in = bb_resize(img_in, threshold(img_in))\n",
        "\n",
        "    return img_in\n",
        "\n",
        "\n",
        "def threshold(img):\n",
        "    \"\"\" Thresholds image according to global parameter. \"\"\"\n",
        "    _, output = cv.threshold(img, THRESH, 255, cv.THRESH_BINARY)\n",
        "    return output\n",
        "\n",
        "\n",
        "def hough_circles(img):\n",
        "    \"\"\"\n",
        "    Apply Hough Circle Transform using global parameters and returns data in\n",
        "    a nice list-of-tuples format. If no circles are found, the empty list is\n",
        "    returned.\n",
        "    :param np.ndarray img: The image to search for circles.\n",
        "    :returns: List of tuples of the form (x, y, radius)\n",
        "    :rtype: list[(int, int, float)]\n",
        "    \"\"\"\n",
        "    global DP, MD, P1, P2, MIN_R, MAX_R\n",
        "    img = img.copy()\n",
        "\n",
        "    # Black out the NW, SW, and SE quadrants to force Hough detection to align\n",
        "    # to notch edge. This is done to hopefully reduce the amount of \"edge\" that\n",
        "    # is left over after subtraction.\n",
        "    h, w = img.shape\n",
        "    half_h, half_w = (int(h / 2), int(w / 2))\n",
        "    cv.rectangle(img, (0, 0), (half_w, h),\n",
        "                 (0, 0, 0), thickness=cv.FILLED)\n",
        "    cv.rectangle(img, (0, h), (w, half_h),\n",
        "                 (0, 0, 0), thickness=cv.FILLED)\n",
        "\n",
        "    circles = cv.HoughCircles(img, cv.HOUGH_GRADIENT, DP, MD,\n",
        "                              param1=P1, param2=P2,\n",
        "                              minRadius=MIN_R, maxRadius=MAX_R)\n",
        "\n",
        "    output = []\n",
        "    if circles is not None:\n",
        "        circles = circles[0]  # Why are tuples buried like this? Bug?\n",
        "        for c in circles[0:]:\n",
        "            output.append((c[0], c[1], c[2]))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def bb_resize(img, img_thresh):\n",
        "    \"\"\"\n",
        "    Resizes an image using bounding boxes. This is done by thresholding the\n",
        "    image and then calculating its bounding box. The shorter dimension of the\n",
        "    bounding box is then expanded (with black pixels) to make the bounding box\n",
        "    square. The pixels in the bounding box are moved to a new image, which is\n",
        "    then resized to a standard resolution.\n",
        "    This effect of this process should be that any eyeball image is roughly\n",
        "    centered at the same position and about the same size. This is important for\n",
        "    notch detection so that a small square can be placed approximately over\n",
        "    where the notch should be in a standardized image.\n",
        "    \"\"\"\n",
        "    x, y, w, h = cv.boundingRect(img_thresh)\n",
        "\n",
        "    # If no bounding rectangle was able to be formed, then the image is\n",
        "    # probably completely unusable. Simply resize to standard resolution and\n",
        "    # move on.\n",
        "    if (w == 0) or (h == 0):\n",
        "        return cv.resize(img, (STD_RES, STD_RES), interpolation=cv.INTER_AREA)\n",
        "\n",
        "    # Destination canvas is square, length of max dimension of the bb.\n",
        "    max_wh = max(w, h)\n",
        "    img_expand = np.zeros((max_wh, max_wh), dtype=np.uint8)\n",
        "\n",
        "    # Copy the bounding box (region of interest) into the center of the\n",
        "    # destination canvas. This will produce black bars on the short side.\n",
        "    diff_w = max_wh - w\n",
        "    diff_h = max_wh - h\n",
        "    half_dw = int(math.floor(diff_w / 2.0))\n",
        "    half_dh = int(math.floor(diff_h / 2.0))\n",
        "    roi = img[y:y + h, x:x + w]\n",
        "    img_expand[half_dh:(half_dh + h), half_dw:(half_dw + w)] = roi\n",
        "\n",
        "    # Resize to our standard resolution.\n",
        "    return cv.resize(img_expand, (STD_RES, STD_RES), interpolation=cv.INTER_AREA)\n",
        "\n",
        "\n",
        "def detect_notch(img, img_thresh):\n",
        "    \"\"\"\n",
        "    Detects if a notch is present in the image, and if so, returns True.\n",
        "    First, the Hough Circle Transform is applied to find a circle corresponding\n",
        "    to the entire eyeball. This circle is subtracted from the thresholded\n",
        "    image of the eyeball. Ideally what is left at this point will be either\n",
        "    a notch, or nothing. Since we will likely pick up \"shreds\" left from the\n",
        "    edges of the subtraction, we contract and dilate at this point to remove\n",
        "    leftovers.\n",
        "    A region of interest is positioned over where notches appear usually,\n",
        "    which is at about the 45 degree mark on the eyeball in the NE quadrant.\n",
        "    Blob detection is run over this ROI. If a blob is detected, it is assumed\n",
        "    that the blob is a notch, and the function can return True.\n",
        "    \"\"\"\n",
        "    circles = hough_circles(img)\n",
        "\n",
        "    # Paint out the first circle detected. Assume that only one circle was\n",
        "    # detected for whole image. If no circles are detected, fail fast and just\n",
        "    # return false.\n",
        "    if circles:\n",
        "        x, y, r = circles[0]\n",
        "        cv.circle(img_thresh, (x, y), r, (0, 0, 0), cv.FILLED)\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "    # Erode what's left to try and remove edges.\n",
        "    img_thresh = cv.erode(img_thresh, np.ones((3, 3), np.uint8))\n",
        "    img_thresh = cv.dilate(img_thresh, np.ones((3, 3), np.uint8))\n",
        "\n",
        "    # Extract a region of interest that is very likely to contain the notch if\n",
        "    # one is present in the image. This corresponds to a small square at about\n",
        "    # the 45 degree mark on the eyeball. Some notches are slightly lower than\n",
        "    # this, so the ROI should be large enough to capture many notch positions.\n",
        "    ratio = 1.0 / 4.0\n",
        "    roi_size = img_thresh.shape[0] * ratio\n",
        "    half_rs = roi_size / 2.0\n",
        "\n",
        "    # Do a little trig to find cartesian coordinates of 45 degrees point.\n",
        "    radius = img_thresh.shape[0] / 2.0\n",
        "    angle = math.pi / 4.0\n",
        "    side = radius * math.sin(angle)\n",
        "\n",
        "    # Get the damned ROI.\n",
        "    x, y = (int(radius + side - half_rs), int(radius - side - half_rs))\n",
        "    roi = img_thresh[y:int(y + roi_size), x:int(x + roi_size)]\n",
        "\n",
        "    # Run blob detection on what's left.\n",
        "    sbd = cv.SimpleBlobDetector_create(BLOB_PARAMS)\n",
        "    keypoints = sbd.detect(roi)\n",
        "\n",
        "    # If keypoints were found, then we assume that a notch was detected.\n",
        "    return bool(keypoints)\n",
        "\n",
        "\n",
        "def draw_hough_circles(img, circles):\n",
        "    \"\"\"\n",
        "    Creates new image from img with circles drawn over it. Will convert the\n",
        "    output image to RGB space.\n",
        "    :param np.ndarray img:\n",
        "    :param list[(int, int, float)] circles: Detected circles.\n",
        "    :rtype: np.ndarray\n",
        "    \"\"\"\n",
        "    if circles:\n",
        "        output = cv.cvtColor(img.copy(), cv.COLOR_GRAY2RGB)\n",
        "        for c in circles:\n",
        "            x, y, r = c\n",
        "            cv.circle(output, (x, y), r, (0, 0, 255), 2)\n",
        "    else:\n",
        "        output = img\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def experiment_threshold(path):\n",
        "    \"\"\"\n",
        "    Launches experiment window for thresholding.\n",
        "    :param str path: Path to the experiment image file.\n",
        "    \"\"\"\n",
        "    img = load_image(path)\n",
        "    _, thresh_img = cv.threshold(img, THRESH, 255, cv.THRESH_BINARY)\n",
        "\n",
        "    # Image windows for this experiment.\n",
        "    t_window = \"Threshold Experiment\"\n",
        "    o_window = \"Original Image\"\n",
        "    cv.namedWindow(t_window, cv.WINDOW_AUTOSIZE)\n",
        "    cv.namedWindow(o_window, cv.WINDOW_AUTOSIZE)\n",
        "\n",
        "    # Callback for parameter slider (instantiated afterward).\n",
        "    def thresh_callback(pos):\n",
        "        #cv.threshold(img, pos, 255, cv.THRESH_BINARY, dst=thresh_img)\n",
        "        #cv.imshow(t_window, thresh_img)\n",
        "        return\n",
        "\n",
        "    # Create the experiment and original image windows.\n",
        "    #cv.createTrackbar(\"Threshold\", t_window, THRESH, 255, thresh_callback)\n",
        "    #cv.imshow(t_window, thresh_img)\n",
        "    #cv.imshow(o_window, img)\n",
        "    #cv.waitKey(0)\n",
        "    return\n",
        "\n",
        "\n",
        "def experiment_hough(path):\n",
        "    \"\"\"\n",
        "    Launches experiment window for the Hough Circle Transformation.\n",
        "    :param str path: Path to the experiment image file.\n",
        "    \"\"\"\n",
        "    # Threshold the image first to get rid of pesky noise.\n",
        "    img = load_image(path)\n",
        "\n",
        "    # Image windows for this experiment.\n",
        "    t_window = \"Hough Circle Transform Experiment\"\n",
        "    cv.namedWindow(t_window, cv.WINDOW_AUTOSIZE)\n",
        "\n",
        "    # Callbacks for parameter sliders (instantiated afterward).\n",
        "    def dp_callback(pos):\n",
        "        global DP\n",
        "        DP = pos\n",
        "        #cv.imshow(t_window, draw_hough_circles(img, hough_circles(img)))\n",
        "        return\n",
        "\n",
        "    def p1_callback(pos):\n",
        "        global P1\n",
        "        P1 = pos\n",
        "        #cv.imshow(t_window, draw_hough_circles(img, hough_circles(img)))\n",
        "        return\n",
        "\n",
        "    def p2_callback(pos):\n",
        "        global P2\n",
        "        P2 = pos\n",
        "        #cv.imshow(t_window, draw_hough_circles(img, hough_circles(img)))\n",
        "        return\n",
        "\n",
        "    # Create the experiment and original image windows.\n",
        "    #cv.createTrackbar(\"DP\", t_window, DP, 10, dp_callback)\n",
        "    #cv.createTrackbar(\"P1\", t_window, P1, 255, p1_callback)\n",
        "    #cv.createTrackbar(\"P2\", t_window, P2, 255, p2_callback)\n",
        "    #cv.imshow(t_window, draw_hough_circles(img, hough_circles(img)))\n",
        "    #cv.waitKey(0)\n",
        "\n",
        "\n",
        "def experiment_edge_detect(path):\n",
        "    img = load_image(path)\n",
        "    img = threshold(img)\n",
        "    edges = cv.Canny(img, LOW_THRESH, MAX_THRESH, apertureSize=KERNEL)\n",
        "\n",
        "    # Image windows for this experiment.\n",
        "    t_window = \"Canny Edge Detect Experiment\"\n",
        "    cv.namedWindow(t_window, cv.WINDOW_AUTOSIZE)\n",
        "\n",
        "    # Callbacks for parameter sliders (instantiated afterward).\n",
        "    def low_thresh_callback(pos):\n",
        "        global LOW_THRESH\n",
        "        LOW_THRESH = pos\n",
        "        edges = cv.Canny(img, LOW_THRESH, MAX_THRESH, apertureSize=KERNEL)\n",
        "        cv.imshow(t_window, edges)\n",
        "        return\n",
        "\n",
        "    #cv.createTrackbar(\"Low Threshold\", t_window, LOW_THRESH, 255, low_thresh_callback)\n",
        "    #cv.imshow(t_window, edges)\n",
        "    #cv.waitKey(0)\n",
        "\n",
        "\n",
        "def experiment_notch_detection(path):\n",
        "    \"\"\" Notch detection via circle subtraction and blob detection. \"\"\"\n",
        "    # Get thresholded image and hough circles.\n",
        "    img = load_image(path)\n",
        "    img_thresh = threshold(img)\n",
        "    circles = hough_circles(img)\n",
        "\n",
        "    # Paint out the first circle detected. Assume that only one circle was\n",
        "    # detected for whole image.\n",
        "    x, y, r = circles[0]\n",
        "    cv.circle(img_thresh, (x, y), r, (0, 0, 0), cv.FILLED)\n",
        "\n",
        "    # Erode what's left to try and remove edges.\n",
        "    img_thresh = cv.erode(img_thresh, np.ones((3, 3), np.uint8))\n",
        "    img_thresh = cv.dilate(img_thresh, np.ones((3, 3), np.uint8))\n",
        "\n",
        "    # Extract a region of interest that is very likely to contain the notch if\n",
        "    # one is present in the image. This corresponds to a small square at about\n",
        "    # the 45 degree mark on the eyeball. Some notches are slightly lower than\n",
        "    # this, so the ROI should be large enough to capture many notch positions.\n",
        "    ratio = 1.0 / 4.0\n",
        "    roi_size = img_thresh.shape[0] * ratio\n",
        "    half_rs = roi_size / 2.0\n",
        "\n",
        "    # Do a little trig to find cartesian coordinates of 45 degrees point.\n",
        "    radius = img_thresh.shape[0] / 2.0\n",
        "    angle = math.pi / 4.0\n",
        "    side = radius * math.sin(angle)\n",
        "\n",
        "    # Get the damned ROI.\n",
        "    x, y = (int(radius + side - half_rs), int(radius - side - half_rs))\n",
        "    cv.rectangle(img, (x, y), (x + int(roi_size), y + int(roi_size)), (255, 255, 255))\n",
        "    roi = img_thresh[y:int(y + roi_size), x:int(x + roi_size)]\n",
        "\n",
        "    # Run blob detection on what's left.\n",
        "    # Set up the detector with default parameters.\n",
        "    blob_params = cv.SimpleBlobDetector_Params()\n",
        "    blob_params.minThreshold = 0.0\n",
        "    blob_params.maxThreshold = THRESH\n",
        "    blob_params.thresholdStep = THRESH / 2\n",
        "    blob_params.filterByArea = False\n",
        "    blob_params.filterByColor = False\n",
        "    blob_params.filterByConvexity = False\n",
        "    blob_params.filterByInertia = True\n",
        "    blob_params.minInertiaRatio = 0.05\n",
        "    blob_params.maxInertiaRatio = 1\n",
        "    sbd = cv.SimpleBlobDetector_create(blob_params)\n",
        "\n",
        "    # Detect blobs.\n",
        "    keypoints = sbd.detect(roi)\n",
        "\n",
        "    # Draw circles around any detected blobs.\n",
        "    # cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle\n",
        "    # corresponds to the size of blob\n",
        "    roi = cv.drawKeypoints(roi, keypoints, np.array([]),\n",
        "                           (0, 0, 255),\n",
        "                           cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "    # Image windows for this experiment.\n",
        "    o_window = \"Original Image\"\n",
        "    t_window = \"Thresholded, Subtracted, Blob-Detected\"\n",
        "    cv.namedWindow(o_window, cv.WINDOW_AUTOSIZE)\n",
        "    cv.namedWindow(t_window, cv.WINDOW_AUTOSIZE)\n",
        "    cv.imshow(o_window, img)\n",
        "    cv.imshow(t_window, roi)\n",
        "    cv.waitKey(0)\n",
        "    return\n",
        "\n",
        "\n",
        "def experiment_bounding_box(path):\n",
        "    \"\"\" Bounding box resizing experiment. \"\"\"\n",
        "\n",
        "    # Calculate initial bounding box via thresholded image.\n",
        "    img = load_image(path, resize=False)\n",
        "    img_thresh = threshold(img)\n",
        "    x, y, w, h = cv.boundingRect(img_thresh)\n",
        "\n",
        "    max_wh = max(w, h)\n",
        "    diff_w = max_wh - w\n",
        "    diff_h = max_wh - h\n",
        "    half_dw = int(math.floor(diff_w / 2.0))\n",
        "    half_dh = int(math.floor(diff_h / 2.0))\n",
        "    img_expand = np.zeros((max_wh, max_wh), dtype=np.uint8)\n",
        "    roi = img[y:y + h, x:x + w]\n",
        "    img_expand[half_dh:(half_dh + h), half_dw:(half_dw + w)] = roi\n",
        "\n",
        "    img_resize = cv.resize(img_expand,\n",
        "                           (STD_RES, STD_RES),\n",
        "                           interpolation=cv.INTER_AREA)\n",
        "\n",
        "    r_window = \"Resized Image\"\n",
        "    #cv.namedWindow(r_window, cv.WINDOW_AUTOSIZE)\n",
        "    #cv.imshow(r_window, img_resize)\n",
        "    #cv.waitKey(0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qmmIVxnCC_1q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir output\n",
        "!mkdir output/train\n",
        "!mkdir output/val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qoipQ8g3C6cs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "\n",
        "dir_path = \"./train\"\n",
        "output_path = \"./output/train\"\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "    os.mkdir(output_path)\n",
        "\n",
        "for file_name in listing_test:\n",
        "    if \"jpeg\" in file_name:\n",
        "      if str(file_name).split(\"_\")[1]==\"right.jpeg\":\n",
        "        path = \"{}/{}\".format(dir_path, file_name)\n",
        "        output = \"{}/{}\".format(output_path, file_name)\n",
        "        new_img = preprocess_image(path)\n",
        "        cv.imwrite(output, new_img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqbidL5arIVu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "\n",
        "dir_path = \"./train\"\n",
        "output_path = \"./output/val\"\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "    os.mkdir(output_path)\n",
        "\n",
        "for file_name in listing_val:\n",
        "    if \"jpeg\" in file_name:\n",
        "      if str(file_name).split(\"_\")[1]==\"right.jpeg\":\n",
        "        path = \"{}/{}\".format(dir_path, file_name)\n",
        "        output = \"{}/{}\".format(output_path, file_name)\n",
        "        new_img = preprocess_image(path)\n",
        "        cv.imwrite(output, new_img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_Z2vUwihn1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f5c89a86-f6b4-481d-eef0-5be7b8ed4418"
      },
      "cell_type": "code",
      "source": [
        "!ls output/val -1 | wc -l\n",
        "!ls output/train -1 | wc -l"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "988\n",
            "2442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6qAqWjJlEiI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0844138b-9e43-43a7-b361-5c1d3beb338f"
      },
      "cell_type": "code",
      "source": [
        "listing = os.listdir(\"output\") \n",
        "print(listing )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['val', 'train']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dPEDFpZ_h7mQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YmOYoBd8Ditw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 756, 756\n",
        "\n",
        "immatrix = []\n",
        "imlabel = []\n",
        "\n",
        "for file in listing:\n",
        "  if str(file).split(\"_\")[1]==\"right.jpeg\":\n",
        "    base = os.path.basename(\"output/\" + file)\n",
        "    fileName = os.path.splitext(base)[0]\n",
        "    imlabel.append(trainLabels.loc[trainLabels.image==fileName, 'level'].values[0])\n",
        "    im = Image.open(\"output/\" + file)   \n",
        "    img = im.resize((img_rows,img_cols))\n",
        "    gray = img.convert('L')\n",
        "    immatrix.append(np.array(gray).flatten())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bCkU7njoE7wC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "immatrix = np.asarray(immatrix)\n",
        "imlabel = np.asarray(imlabel)\n",
        "#from sklearn.utils import shuffle\n",
        "\n",
        "#data,Label = shuffle(immatrix,imlabel, random_state=2)\n",
        "train_data = [immatrix,imlabel]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZiiU7Jo_8BZu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#np.set_printoptions(threshold=np.inf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CY8QNuPw15E0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "30cb761f-1cfd-4e1d-d12a-f878d5566988"
      },
      "cell_type": "code",
      "source": [
        "!pip install imblearn"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imblearn\n",
            "  Downloading https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
            "Collecting imbalanced-learn (from imblearn)\n",
            "  Downloading https://files.pythonhosted.org/packages/80/a4/900463a3c0af082aed9c5a43f4ec317a9469710c5ef80496c9abc26ed0ca/imbalanced_learn-0.3.3-py3-none-any.whl (144kB)\n",
            "\u001b[K    100% |████████████████████████████████| 153kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn)\n",
            "Installing collected packages: imbalanced-learn, imblearn\n",
            "Successfully installed imbalanced-learn-0.3.3 imblearn-0.0\n",
            "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FIN3cZXL5Has",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "22850913-e7c9-4895-9b8c-bf80d9a50195"
      },
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "(X, y) = (train_data[0],train_data[1])\n",
        "#rus = RandomUnderSampler(random_state=42)\n",
        "#X,y = rus.fit_sample(X, y)\n",
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "# STEP 1: split X and y into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qCsA_2qU2uyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6237a0be-15db-4d2d-c3bc-37b2c80043f8"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "Un2VX3kJ48Jl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f= open(\"dataX3\",\"wb+\")\n",
        "f.close()\n",
        "f= open(\"datay3\",\"wb+\")\n",
        "f.close()\n",
        "dataX= open(\"dataX3\",\"wb+\")\n",
        "datay= open(\"datay3\",\"wb+\")\n",
        "np.save(dataX,X)\n",
        "np.save(datay,y)\n",
        "dataX.close()\n",
        "datay.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2aMdFzJa6mZ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataX= open(\"dataX\",\"rb+\")\n",
        "new = np.load(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qC52uvnc60Vp",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:20797/content/dataX3": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNTA0IChHYXRld2F5IFRpbWVvdXQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj41MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1455"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 504,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1714
        },
        "outputId": "65a8593f-7fd2-432d-9c0d-de3c7d04f863"
      },
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=M\n",
        "from google.colab import files\n",
        "files.download(\"dataX3\")\n",
        "files.download(\"datay3\")\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4317M\r\n",
            "drwxr-xr-x 1 root root    1M Apr 20 06:32 datalab\r\n",
            "-rw-r--r-- 1 root root 1378M Apr 20 07:01 dataX\r\n",
            "-rw-r--r-- 1 root root  626M Apr 20 04:03 dataX2\r\n",
            "-rw-r--r-- 1 root root  626M Apr 20 04:00 dataX (2)\r\n",
            "-rw-r--r-- 1 root root 1378M Apr 20 07:02 dataX3\r\n",
            "-rw-r--r-- 1 root root    1M Apr 20 07:01 datay\r\n",
            "-rw-r--r-- 1 root root    1M Apr 20 04:03 datay2\r\n",
            "-rw-r--r-- 1 root root    1M Apr 20 04:00 datay (2)\r\n",
            "-rw-r--r-- 1 root root    1M Apr 20 07:02 datay3\r\n",
            "-rw-r--r-- 1 root root  307M Apr 20 04:04 face-swap.zip\r\n",
            "drwxr-xr-x 2 root root    1M Apr 20 06:57 output\r\n",
            "drwxr-xr-x 2 root root    2M Feb 12  2015 train\r\n",
            "-rw-r--r-- 1 root root    1M Feb  6  2015 trainLabels.csv\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 60012, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 696, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 775, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 47502, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 696, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 775, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-a9ac518a0ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls -l --block-size=M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataX3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datay3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    170\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     84\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m     85\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: Failed to download: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6Wf1MiSv17sA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#batch_size to train\n",
        "batch_size = 512\n",
        "# number of output classes\n",
        "nb_classes = 5\n",
        "# number of epochs to train\n",
        "nb_epoch = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oiYatckHzFC_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# number of convolutional filters to use\n",
        "nb_filters = 30\n",
        "# size of pooling area for max pooling\n",
        "nb_pool = 2\n",
        "# convolution kernel size\n",
        "nb_conv = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fA0ftjIB1O0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a020e43a-3677-4883-c977-927f1eaccea6"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "img_rows, img_cols = 512, 512\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "#X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "#X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2002, 262144)\n",
            "(501, 262144)\n",
            "X_train shape: (2002, 512, 512, 1)\n",
            "2002 train samples\n",
            "501 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kLYGKkKBAwkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "7c4ba973-703d-47ea-d3d4-c9d0e4e8242d"
      },
      "cell_type": "code",
      "source": [
        "del train_data\n",
        "del data\n",
        "del Label"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-da3ecec3085a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mLabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "R9JT_jPnM_oz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ccf4ed01-772c-4022-947e-2c280300eff5"
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile({'title': 'dataX3'})\n",
        "uploaded.SetContentFile('dataX3')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile({'title': 'datay3'})\n",
        "uploaded.SetContentFile('datay3')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1CQgtc0bnkDR9-_9MXbqTsqalgU3cOaop\n",
            "Uploaded file with ID 1TheWMuwhpp8lDu2dRdvVIS6Gy4if4DtW\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-tKpC8rSVbcL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "3fcee886-e394-4594-89ce-47ad4d7b8ef9"
      },
      "cell_type": "code",
      "source": [
        "!wget https://cdn-04.anonfile.com/p7w3m0d5be/27a986a8-1524195658/face-swap.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-20 03:39:35--  https://cdn-04.anonfile.com/p7w3m0d5be/27a986a8-1524195658/face-swap.zip\n",
            "Resolving cdn-04.anonfile.com (cdn-04.anonfile.com)... 185.147.237.151\n",
            "Connecting to cdn-04.anonfile.com (cdn-04.anonfile.com)|185.147.237.151|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 321878744 (307M) [application/zip]\n",
            "Saving to: ‘face-swap.zip’\n",
            "\n",
            "face-swap.zip         7%[>                   ]  23.97M   303KB/s    eta 16m 8s "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "face-swap.zip        99%[==================> ] 306.76M   344KB/s    eta 3s     "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rface-swap.zip        99%[==================> ] 306.76M   374KB/s    eta 1s     \rface-swap.zip       100%[===================>] 306.97M   400KB/s    in 24m 45s \r\n",
            "\r\n",
            "2018-04-20 04:04:21 (212 KB/s) - ‘face-swap.zip’ saved [321878744/321878744]\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WAwF-HeDOQ0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7037f4db-105d-40d0-8156-9cb2d944f50d"
      },
      "cell_type": "code",
      "source": [
        "uploaded = drive.CreateFile({'title': 'face-swap.zip'})\n",
        "uploaded.SetContentFile('face-swap.zip')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1r4t7QxPa4vf9vlPQylT_ianfYiHcJ2bA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "umEKCSmT1Qy8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "2499fcf1-77be-4cc3-dca3-483e3488d9f0"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD,RMSprop,adam\n",
        "import keras\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.9999, epsilon=None, decay=0.0001, amsgrad=False)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
        "                        border_mode='valid',\n",
        "                        input_shape=(img_cols, img_rows, 1)))\n",
        "convout1 = Activation('relu')\n",
        "model.add(convout1)\n",
        "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
        "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
        "model.add(Dropout(0.5))\n",
        "convout2 = Activation('relu')\n",
        "model.add(convout2)\n",
        "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
        "model.add(MaxPooling2D(pool_size=(nb_pool+1, nb_pool+1)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "convout3 = Activation('relu')\n",
        "model.add(convout3)\n",
        "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
        "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(680))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (4, 4), input_shape=(512, 512,..., padding=\"valid\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (4, 4))`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (3, 3))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "V0HcgSst1cpD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w9xT1RoC1hvJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create generators  - training data will be augmented images\n",
        "validationdatagenerator = ImageDataGenerator()\n",
        "traindatagenerator = ImageDataGenerator()\n",
        "batchsize= 64\n",
        "train_generator=traindatagenerator.flow(X_train, Y_train, batch_size=batchsize) \n",
        "validation_generator=validationdatagenerator.flow(X_test, Y_test,batch_size=batchsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JaHp54ZSGDGw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del y_test\n",
        "del y\n",
        "del y_train\n",
        "del immatrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6NhPT4zeLrZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1e28e74c-cb2a-47d2-b4bb-0dd113f2e1b2"
      },
      "cell_type": "code",
      "source": [
        "!free -m"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\r\n",
            "Mem:          13029        6773         272         255        5982        5752\r\n",
            "Swap:             0           0           0\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zf4SP1eR3oNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3832
        },
        "outputId": "51fff548-caa4-4253-e5d7-fcb6463457ff"
      },
      "cell_type": "code",
      "source": [
        "#hist = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_split=0.2)\n",
        "model.fit_generator(train_generator, steps_per_epoch=int(len(X_train)/batchsize), epochs=1000, validation_data=validation_generator, validation_steps=int(len(X_test)/batchsize))\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,30,506,506] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@max_pooling2d_1/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_2/BiasAdd, max_pooling2d_1/MaxPool, training/Adam/gradients/AddN_4)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-34284e28c0f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,30,506,506] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@max_pooling2d_1/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_2/BiasAdd, max_pooling2d_1/MaxPool, training/Adam/gradients/AddN_4)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training/Adam/gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-50-48975be7e8ce>\", line 1, in <module>\n    hist = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_split=0.2)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 963, in fit\n    validation_steps=validation_steps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1682, in fit\n    self._make_train_function()\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 445, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2515, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 611, in gradients\n    lambda: grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 377, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 611, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_grad.py\", line 604, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\"))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 3252, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'max_pooling2d_1/MaxPool', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-cb055bfe3e93>\", line 17, in <module>\n    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 492, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\", line 158, in call\n    data_format=self.data_format)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\", line 221, in _pooling_function\n    pool_mode='max')\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 3657, in pool2d\n    data_format=tf_data_format)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2124, in max_pool\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2981, in _max_pool\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,30,506,506] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@max_pooling2d_1/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_2/BiasAdd, max_pooling2d_1/MaxPool, training/Adam/gradients/AddN_4)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fSSsVayr3qQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "3cb2e19d-a241-445e-f1c2-36af9863ae5a"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 509, 509, 30)      510       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 509, 509, 30)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 506, 506, 30)      14430     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 253, 253, 30)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 253, 253, 30)      0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 253, 253, 30)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 251, 251, 30)      8130      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 83, 83, 30)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 83, 83, 30)        0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 83, 83, 30)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 81, 81, 30)        8130      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 20, 20, 30)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 20, 20, 30)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 680)               8160680   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 680)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               87168     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 8,279,693\n",
            "Trainable params: 8,279,693\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ybb3XXiuPBi9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Gv1fqAmwDuku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e439fda6-e5fa-4d32-a97c-fde1a26d9b87"
      },
      "cell_type": "code",
      "source": [
        "!free -m\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\r\n",
            "Mem:          13029         342        5394           0        7292       12438\r\n",
            "Swap:             0           0           0\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TrQbkgP3M1wS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQyIK7nM7G3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "d8444fb9-f9d3-44e1-8b01-3e13942f21bb"
      },
      "cell_type": "code",
      "source": [
        "y[0:4]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-4b911c1af6a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "tsNnOGz2P4-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5474
        },
        "outputId": "97f3cfc1-e5e8-4850-9933-857431a9db1e"
      },
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.00392157],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.00392157],\n",
              "         [0.00392157]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.00392157],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.00392157]]],\n",
              "\n",
              "\n",
              "       [[[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.00392157],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.00392157]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.00392157],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]],\n",
              "\n",
              "        [[0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         ...,\n",
              "         [0.        ],\n",
              "         [0.        ],\n",
              "         [0.        ]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "2d7Z3TDl7ZuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "351ea301-9c99-459e-fcda-d6d8e4e81fb3"
      },
      "cell_type": "code",
      "source": [
        "!add-apt-repository ppa:alessandro-strada/google-drive-ocamlfuse-beta\n",
        "!apt-get update\n",
        "!apt-get install google-drive-ocamlfuse"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/sh: 1: add-apt-repository: not found\n",
            "Get:1 http://security.ubuntu.com/ubuntu artful-security InRelease [83.2 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu artful InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu artful-updates InRelease [88.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu artful-backports InRelease [74.6 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu artful-security/universe Sources [20.5 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu artful-security/main amd64 Packages [204 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu artful-updates/universe Sources [42.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu artful-updates/universe amd64 Packages [138 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu artful-security/universe amd64 Packages [76.6 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu artful-security/multiverse amd64 Packages [1,822 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu artful-updates/multiverse amd64 Packages [4,380 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu artful-updates/main amd64 Packages [329 kB]\n",
            "Fetched 1,063 kB in 1s (572 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package google-drive-ocamlfuse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NLUHCtci7c_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9c4195b-3600-4c65-e9a1-c20aad4a516b"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/sh: 1: google-drive-ocamlfuse: not found\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VhYSqVN7_k8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "f94715ed-cd5e-46ac-ec6e-4a4147059904"
      },
      "cell_type": "code",
      "source": [
        "!df -BG "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filesystem     1G-blocks  Used Available Use% Mounted on\r\n",
            "overlay             359G    6G      335G   2% /\r\n",
            "tmpfs                 7G    0G        7G   0% /dev\r\n",
            "tmpfs                 7G    0G        7G   0% /sys/fs/cgroup\r\n",
            "/dev/root             2G    1G        1G  44% /opt/bin\r\n",
            "tmpfs                 7G    1G        7G   4% /usr/lib64-nvidia\r\n",
            "/dev/sda1           365G    8G      358G   2% /etc/hosts\r\n",
            "shm                   1G    0G        1G   0% /dev/shm\r\n",
            "tmpfs                 7G    0G        7G   0% /sys/firmware\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNuLlBwcMTJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "0b79cb0b-f3fb-4f95-8439-2aa6a6cd004d"
      },
      "cell_type": "code",
      "source": [
        "!df -BG "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filesystem     1G-blocks  Used Available Use% Mounted on\r\n",
            "overlay             359G    6G      335G   2% /\r\n",
            "tmpfs                 7G    0G        7G   0% /dev\r\n",
            "tmpfs                 7G    0G        7G   0% /sys/fs/cgroup\r\n",
            "/dev/root             2G    1G        1G  44% /opt/bin\r\n",
            "tmpfs                 7G    1G        7G   4% /usr/lib64-nvidia\r\n",
            "/dev/sda1           365G    8G      358G   3% /etc/hosts\r\n",
            "shm                   1G    0G        1G   0% /dev/shm\r\n",
            "tmpfs                 7G    0G        7G   0% /sys/firmware\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XeeNQ5fNMZhz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ph5ZDShIMo0Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j7-DCONdNaGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tEOJNoYANhWk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzqR8lgIOQ20",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mG5mv9VxTk2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3f4fcd2-9333-4f61-f862-42df5ecb5525"
      },
      "cell_type": "code",
      "source": [
        "!go get github.com/google/skicka"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/sh: 1: go: not found\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ogM4ki6nUWXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3682a0cc-bb41-4d32-8500-3043f9b09ded"
      },
      "cell_type": "code",
      "source": [
        "!ls datalab"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  sampleSubmission.csv.zip  sample.zip\ttrainLabels.csv.zip\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PkPS5uig-VY2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E5_GQoOV-ePN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#second way"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SfRGzKZekssx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir output/train/0\n",
        "!mkdir output/train/1\n",
        "!mkdir output/train/2\n",
        "!mkdir output/train/3\n",
        "!mkdir output/train/4\n",
        "!mkdir output/val/0\n",
        "!mkdir output/val/1\n",
        "!mkdir output/val/2\n",
        "!mkdir output/val/3\n",
        "!mkdir output/val/4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pXrRSElFk8-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "listing_train = os.listdir(\"output/train\")\n",
        "listing_val = os.listdir(\"output/val\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ISa-er3zwEri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5e16d3d-fea6-44db-e88e-74554db580a4"
      },
      "cell_type": "code",
      "source": [
        "file=listing_train[0]\n",
        "base = os.path.basename(\"output/\" + file)\n",
        "print( os.path.splitext(file)[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1666_right\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oJ3K-PbPw3QG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "base_dir = \"output/val/\"\n",
        "\n",
        "for file in listing_val:\n",
        "  try:\n",
        "    fileName = os.path.splitext(file)[0]\n",
        "    folder_name = trainLabels.loc[trainLabels.image==fileName, 'level'].values[0]  \n",
        "    os.rename(base_dir + file, base_dir + str(folder_name) + \"/\" + file )\n",
        "  except:\n",
        "    pass\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CZsXxqA1kPei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "base_dir = \"output/train/\"\n",
        "\n",
        "for file in listing_train:\n",
        "  try:\n",
        "    fileName = os.path.splitext(file)[0]\n",
        "    folder_name = trainLabels.loc[trainLabels.image==fileName, 'level'].values[0]  \n",
        "    os.rename(base_dir + file, base_dir + str(folder_name) + \"/\" + file )\n",
        "  except:\n",
        "    pass\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9O3YYXUO_8bd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        " \n",
        "main_model = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(224, 224, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iQ53mCYe999q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IPj1BWLYjsTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a37307b9-2c06-44be-baff-377a95197469"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_gen_args = dict(samplewise_std_normalization=True)\n",
        "\n",
        "datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        " \n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    \"./output/train\",\n",
        "    target_size=(750, 750),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:664: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 2442 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5yT1N2v2_iy0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wC6aBAX5j55H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "dfc0a021-856b-48ed-9108-bfd19d7f9fb3"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_gen_args = dict(samplewise_std_normalization=True)\n",
        "\n",
        "datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        " \n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    \"./output/val\",\n",
        "    target_size=(750, 750),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 991 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:664: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4bTfP4RW_lBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "9ed48dd0-c41a-494b-ce79-3f042d394de7"
      },
      "cell_type": "code",
      "source": [
        "train_dir =\"./output/train\"\n",
        "val_dir = \"./output/val\"\n",
        "\n",
        "datagen = ImageDataGenerator(samplewise_std_normalization=True)\n",
        "process_target = True\n",
        "\n",
        "flow_val=datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "flow_train=datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "counter =0\n",
        "\n",
        "def batch_generator_val(datagen,flow_val):\n",
        "  number_of_batches =12\n",
        "  global counter\n",
        "  while True:\n",
        "    counter = counter +1\n",
        "    x_batch = next(flow_val,counter)\n",
        "    x = main_model.predict(x_batch[0])\n",
        "    y = x_batch[1]\n",
        "    res_batch = (x,y)\n",
        "    yield res_batch\n",
        "  \n",
        "def batch_generator_train(datagen,flow_train):\n",
        "  number_of_batches =8  \n",
        "  global counter \n",
        "  while True:\n",
        "    x_batch = next(flow_train,counter)\n",
        "    x = main_model.predict(x_batch[0])\n",
        "    y = x_batch[1]\n",
        "    res_batch = (x,y)\n",
        "    yield res_batch"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:664: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 988 images belonging to 5 classes.\n",
            "Found 2442 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jnny20lBA3ll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_generator = batch_generator_val(datagen,flow_val)\n",
        "train_generator = batch_generator_train(datagen,flow_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HuNZbbZ6ATZo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD,RMSprop,adam\n",
        "import keras\n",
        "from keras import layers, models, optimizers\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.9999, epsilon=1e-07, decay=0.00001, amsgrad=False)\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_shape=(7,7,512)))\n",
        "model.add(Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-nLCFM6EAlXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "outputId": "e705460d-bd2d-43ff-9baa-ba60371ae87b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "hist_plot = model.fit_generator(train_generator, steps_per_epoch=90, workers=0 ,epochs=50, validation_data=val_generator, validation_steps=30, use_multiprocessing=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "90/90 [==============================] - 28s 316ms/step - loss: 1.0042 - acc: 0.6944 - val_loss: 0.8090 - val_acc: 0.7444\n",
            "Epoch 2/50\n",
            "90/90 [==============================] - 27s 302ms/step - loss: 0.9622 - acc: 0.7046 - val_loss: 0.7801 - val_acc: 0.7639\n",
            "Epoch 3/50\n",
            "90/90 [==============================] - 28s 307ms/step - loss: 0.8702 - acc: 0.7342 - val_loss: 0.7566 - val_acc: 0.7670\n",
            "Epoch 4/50\n",
            "80/90 [=========================>....] - ETA: 2s - loss: 0.8409 - acc: 0.7271"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 26s 293ms/step - loss: 0.8433 - acc: 0.7269 - val_loss: 0.8403 - val_acc: 0.7472\n",
            "Epoch 5/50\n",
            "90/90 [==============================] - 26s 292ms/step - loss: 0.7834 - acc: 0.7556 - val_loss: 0.7640 - val_acc: 0.7611\n",
            "Epoch 6/50\n",
            "90/90 [==============================] - 26s 292ms/step - loss: 0.7376 - acc: 0.7676 - val_loss: 0.9382 - val_acc: 0.7017\n",
            "Epoch 7/50\n",
            "90/90 [==============================] - 27s 294ms/step - loss: 0.8531 - acc: 0.7102 - val_loss: 0.8201 - val_acc: 0.7222\n",
            "Epoch 8/50\n",
            " 8/90 [=>............................] - ETA: 18s - loss: 0.6776 - acc: 0.7604"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 26s 294ms/step - loss: 0.7396 - acc: 0.7528 - val_loss: 0.6968 - val_acc: 0.7667\n",
            "Epoch 9/50\n",
            "90/90 [==============================] - 26s 291ms/step - loss: 0.7305 - acc: 0.7481 - val_loss: 0.7676 - val_acc: 0.7528\n",
            "Epoch 10/50\n",
            "90/90 [==============================] - 26s 294ms/step - loss: 0.7324 - acc: 0.7444 - val_loss: 0.8513 - val_acc: 0.7472\n",
            "Epoch 11/50\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.6970 - acc: 0.7575"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r90/90 [==============================] - 27s 296ms/step - loss: 0.7004 - acc: 0.7565 - val_loss: 0.7966 - val_acc: 0.7667\n",
            "Epoch 12/50\n",
            "90/90 [==============================] - 26s 294ms/step - loss: 0.6477 - acc: 0.7778 - val_loss: 0.7972 - val_acc: 0.7528\n",
            "Epoch 13/50\n",
            "90/90 [==============================] - 26s 294ms/step - loss: 0.7232 - acc: 0.7407 - val_loss: 0.7652 - val_acc: 0.7444\n",
            "Epoch 14/50\n",
            "61/90 [===================>..........] - ETA: 6s - loss: 0.7193 - acc: 0.7596"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 26s 293ms/step - loss: 0.7042 - acc: 0.7611 - val_loss: 0.7496 - val_acc: 0.7415\n",
            "Epoch 15/50\n",
            "90/90 [==============================] - 27s 295ms/step - loss: 0.6352 - acc: 0.7769 - val_loss: 0.8164 - val_acc: 0.7444\n",
            "Epoch 16/50\n",
            "90/90 [==============================] - 26s 291ms/step - loss: 0.6700 - acc: 0.7694 - val_loss: 0.7995 - val_acc: 0.7222\n",
            "Epoch 17/50\n",
            "90/90 [==============================] - 26s 291ms/step - loss: 0.6293 - acc: 0.7731 - val_loss: 0.7803 - val_acc: 0.7699\n",
            "Epoch 18/50\n",
            " 4/90 [>.............................] - ETA: 18s - loss: 0.4659 - acc: 0.8333"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 26s 290ms/step - loss: 0.6555 - acc: 0.7685 - val_loss: 0.7496 - val_acc: 0.7750\n",
            "Epoch 19/50\n",
            "90/90 [==============================] - 26s 290ms/step - loss: 0.6094 - acc: 0.7805 - val_loss: 0.7471 - val_acc: 0.7639\n",
            "Epoch 20/50\n",
            "90/90 [==============================] - 26s 290ms/step - loss: 0.6238 - acc: 0.7750 - val_loss: 0.8752 - val_acc: 0.7244\n",
            "Epoch 21/50\n",
            "87/90 [============================>.] - ETA: 0s - loss: 0.6247 - acc: 0.7759"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 26s 290ms/step - loss: 0.6219 - acc: 0.7787 - val_loss: 0.8517 - val_acc: 0.7417\n",
            "Epoch 22/50\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.5713 - acc: 0.7949"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fUNXjJq2ycuP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# number of convolutional filters to use\n",
        "nb_filters = 30\n",
        "# size of pooling area for max pooling\n",
        "nb_pool = 2\n",
        "# convolution kernel size\n",
        "nb_conv = 4\n",
        "\n",
        "\n",
        "# number of output classes\n",
        "nb_classes = 5\n",
        "# number of epochs to train\n",
        "nb_epoch = 64\n",
        "\n",
        "img_rows, img_cols = 750,750"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sW4Tm-N6pFHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "413e4c42-ced4-4484-91f1-f711667876d2"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD,RMSprop,adam\n",
        "import keras\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=3e-03, beta_1=0.9, beta_2=0.9999, epsilon=None, decay=0.00001, amsgrad=False)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
        "                        border_mode='valid',\n",
        "                        input_shape=(img_cols, img_rows, 3)))\n",
        "convout1 = Activation('relu')\n",
        "model.add(convout1)\n",
        "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
        "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
        "model.add(Dropout(0.5))\n",
        "convout2 = Activation('relu')\n",
        "model.add(convout2)\n",
        "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
        "model.add(MaxPooling2D(pool_size=(nb_pool+1, nb_pool+1)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "convout3 = Activation('relu')\n",
        "model.add(convout3)\n",
        "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
        "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "convout4 = Activation('relu')\n",
        "model.add(convout4)\n",
        "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
        "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(680))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (4, 4), input_shape=(750, 750,..., padding=\"valid\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (4, 4))`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (3, 3))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "13XLt49SKSmJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=7 * 7 * 512))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vCeXLoKFxlwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1030
        },
        "outputId": "c07dc804-4288-4a97-fccd-1155673a6d49"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 221, 221, 30)      1470      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 221, 221, 30)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 218, 218, 30)      14430     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 109, 109, 30)      0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 109, 109, 30)      0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 109, 109, 30)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 107, 107, 30)      8130      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 35, 35, 30)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 35, 35, 30)        0         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 35, 35, 30)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 33, 33, 30)        8130      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 30)          0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 8, 8, 30)          0         \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 8, 8, 30)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 6, 6, 30)          8130      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 30)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1, 1, 30)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 680)               21080     \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 680)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               87168     \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 149,183\n",
            "Trainable params: 149,183\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "23_gz3wF_DI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3S7OHKu8y218",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5538
        },
        "outputId": "c7a599a9-2dc3-476b-b427-0e9e1530689a"
      },
      "cell_type": "code",
      "source": [
        "#hist = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_split=0.2)\n",
        "history = model.fit_generator(train_generator, steps_per_epoch=64, epochs=1000, validation_data=val_generator, validation_steps=50)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "64/64 [==============================] - 70s 1s/step - loss: 0.9818 - acc: 0.7435 - val_loss: 1.3318 - val_acc: 0.7500\n",
            "Epoch 2/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9728 - acc: 0.7253 - val_loss: 1.2682 - val_acc: 0.7500\n",
            "Epoch 3/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9412 - acc: 0.7279 - val_loss: 1.0416 - val_acc: 0.7500\n",
            "Epoch 4/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9136 - acc: 0.7383 - val_loss: 0.9915 - val_acc: 0.7500\n",
            "Epoch 5/1000\n",
            "39/64 [=================>............] - ETA: 21s - loss: 0.9133 - acc: 0.7350"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.9306 - acc: 0.7279 - val_loss: 1.0204 - val_acc: 0.7500\n",
            "Epoch 6/1000\n",
            "63/64 [============================>.] - ETA: 0s - loss: 0.8907 - acc: 0.7474Epoch 7/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9246 - acc: 0.7279 - val_loss: 0.9490 - val_acc: 0.7500\n",
            "Epoch 8/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9292 - acc: 0.7253 - val_loss: 0.9061 - val_acc: 0.7500\n",
            "Epoch 9/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8387 - acc: 0.7630 - val_loss: 0.8822 - val_acc: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8961 - acc: 0.7305 - val_loss: 0.8806 - val_acc: 0.7500\n",
            "Epoch 11/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9003 - acc: 0.7357 - val_loss: 0.8979 - val_acc: 0.7500\n",
            "Epoch 12/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8597 - acc: 0.7448 - val_loss: 0.8883 - val_acc: 0.7500\n",
            "Epoch 13/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9669 - acc: 0.7201 - val_loss: 0.9151 - val_acc: 0.7500\n",
            "Epoch 14/1000\n",
            "38/64 [================>.............] - ETA: 21s - loss: 0.9061 - acc: 0.7127"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.9234 - acc: 0.7109 - val_loss: 0.8961 - val_acc: 0.7500\n",
            "Epoch 15/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8651 - acc: 0.7461 - val_loss: 0.8645 - val_acc: 0.7500\n",
            "Epoch 16/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9321 - acc: 0.7318 - val_loss: 0.8653 - val_acc: 0.7500\n",
            "Epoch 17/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8439 - acc: 0.7487 - val_loss: 0.8628 - val_acc: 0.7500\n",
            "Epoch 18/1000\n",
            "49/64 [=====================>........] - ETA: 12s - loss: 0.9517 - acc: 0.7177"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.9475 - acc: 0.7161 - val_loss: 0.8680 - val_acc: 0.7500\n",
            "Epoch 19/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8716 - acc: 0.7461 - val_loss: 0.8599 - val_acc: 0.7500\n",
            "Epoch 20/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8770 - acc: 0.7500 - val_loss: 0.8622 - val_acc: 0.7500\n",
            "Epoch 21/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8786 - acc: 0.7500 - val_loss: 0.8678 - val_acc: 0.7500\n",
            "Epoch 22/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8529 - acc: 0.7516"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8703 - acc: 0.7461 - val_loss: 0.8814 - val_acc: 0.7500\n",
            "Epoch 23/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9613 - acc: 0.7005 - val_loss: 0.8751 - val_acc: 0.7500\n",
            "Epoch 24/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8563 - acc: 0.7539 - val_loss: 0.8707 - val_acc: 0.7500\n",
            "Epoch 25/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9044 - acc: 0.7253 - val_loss: 0.8700 - val_acc: 0.7500\n",
            "Epoch 26/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.9039 - acc: 0.7304"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.9122 - acc: 0.7266 - val_loss: 0.8791 - val_acc: 0.7500\n",
            "Epoch 27/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8994 - acc: 0.7370 - val_loss: 0.8650 - val_acc: 0.7500\n",
            "Epoch 28/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9250 - acc: 0.7240 - val_loss: 0.8862 - val_acc: 0.7500\n",
            "Epoch 29/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8677 - acc: 0.7396 - val_loss: 0.8659 - val_acc: 0.7500\n",
            "Epoch 30/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8828 - acc: 0.7320"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8885 - acc: 0.7318 - val_loss: 0.8645 - val_acc: 0.7500\n",
            "Epoch 31/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8615 - acc: 0.7383 - val_loss: 0.8667 - val_acc: 0.7500\n",
            "Epoch 32/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8766 - acc: 0.7396 - val_loss: 0.8733 - val_acc: 0.7500\n",
            "Epoch 33/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8846 - acc: 0.7305 - val_loss: 0.8727 - val_acc: 0.7500\n",
            "Epoch 34/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8524 - acc: 0.7402"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8632 - acc: 0.7357 - val_loss: 0.8745 - val_acc: 0.7500\n",
            "Epoch 35/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9097 - acc: 0.7383 - val_loss: 0.8676 - val_acc: 0.7500\n",
            "Epoch 36/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8862 - acc: 0.7357 - val_loss: 0.8620 - val_acc: 0.7500\n",
            "Epoch 37/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8646 - acc: 0.7318 - val_loss: 0.8647 - val_acc: 0.7500\n",
            "Epoch 38/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8915 - acc: 0.7435"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8950 - acc: 0.7409 - val_loss: 0.8668 - val_acc: 0.7500\n",
            "Epoch 39/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8770 - acc: 0.7396 - val_loss: 0.8620 - val_acc: 0.7500\n",
            "Epoch 40/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9023 - acc: 0.7201 - val_loss: 0.8933 - val_acc: 0.7500\n",
            "Epoch 41/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8849 - acc: 0.7357 - val_loss: 0.8714 - val_acc: 0.7500\n",
            "Epoch 42/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8805 - acc: 0.7239"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8592 - acc: 0.7370 - val_loss: 0.8717 - val_acc: 0.7500\n",
            "Epoch 43/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9084 - acc: 0.7305 - val_loss: 0.8649 - val_acc: 0.7500\n",
            "Epoch 44/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8430 - acc: 0.7565 - val_loss: 0.8640 - val_acc: 0.7500\n",
            "Epoch 45/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8717 - acc: 0.7435 - val_loss: 0.8631 - val_acc: 0.7500\n",
            "Epoch 46/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.9453 - acc: 0.7026"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.9145 - acc: 0.7174 - val_loss: 0.8634 - val_acc: 0.7500\n",
            "Epoch 47/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8777 - acc: 0.7370 - val_loss: 0.8610 - val_acc: 0.7500\n",
            "Epoch 48/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9225 - acc: 0.7109 - val_loss: 0.8630 - val_acc: 0.7500\n",
            "Epoch 49/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8529 - acc: 0.7461 - val_loss: 0.8622 - val_acc: 0.7500\n",
            "Epoch 50/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8782 - acc: 0.7353"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8946 - acc: 0.7292 - val_loss: 0.8659 - val_acc: 0.7500\n",
            "Epoch 51/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9050 - acc: 0.7187 - val_loss: 0.8674 - val_acc: 0.7500\n",
            "Epoch 52/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8716 - acc: 0.7487 - val_loss: 0.8603 - val_acc: 0.7500\n",
            "Epoch 53/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8300 - acc: 0.7513 - val_loss: 0.8629 - val_acc: 0.7500\n",
            "Epoch 54/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.9221 - acc: 0.7173"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8833 - acc: 0.7318 - val_loss: 0.8688 - val_acc: 0.7500\n",
            "Epoch 55/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9216 - acc: 0.7174 - val_loss: 0.8654 - val_acc: 0.7500\n",
            "Epoch 56/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8574 - acc: 0.7344 - val_loss: 0.8678 - val_acc: 0.7500\n",
            "Epoch 57/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8571 - acc: 0.7422 - val_loss: 0.8728 - val_acc: 0.7500\n",
            "Epoch 58/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.9124 - acc: 0.7255"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.9048 - acc: 0.7305 - val_loss: 0.8597 - val_acc: 0.7500\n",
            "Epoch 59/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8890 - acc: 0.7344 - val_loss: 0.8712 - val_acc: 0.7500\n",
            "Epoch 60/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8814 - acc: 0.7331 - val_loss: 0.8620 - val_acc: 0.7500\n",
            "Epoch 61/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8960 - acc: 0.7253 - val_loss: 0.8623 - val_acc: 0.7500\n",
            "Epoch 62/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8323 - acc: 0.7533"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 68s 1s/step - loss: 0.8344 - acc: 0.7539 - val_loss: 0.8641 - val_acc: 0.7500\n",
            "Epoch 63/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8875 - acc: 0.7344 - val_loss: 0.8662 - val_acc: 0.7500\n",
            "Epoch 64/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9060 - acc: 0.7201 - val_loss: 0.8763 - val_acc: 0.7500\n",
            "Epoch 65/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8514 - acc: 0.7474 - val_loss: 0.8611 - val_acc: 0.7500\n",
            "Epoch 66/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8423 - acc: 0.7582"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 68s 1s/step - loss: 0.8586 - acc: 0.7474 - val_loss: 0.8625 - val_acc: 0.7500\n",
            "Epoch 67/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8680 - acc: 0.7422 - val_loss: 0.8606 - val_acc: 0.7500\n",
            "Epoch 68/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.8966 - acc: 0.7266 - val_loss: 0.8635 - val_acc: 0.7500\n",
            "Epoch 69/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.8674 - acc: 0.7201 - val_loss: 0.8697 - val_acc: 0.7500\n",
            "Epoch 70/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8880 - acc: 0.7353"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 68s 1s/step - loss: 0.8815 - acc: 0.7383 - val_loss: 0.8671 - val_acc: 0.7500\n",
            "Epoch 71/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9016 - acc: 0.7279 - val_loss: 0.8727 - val_acc: 0.7500\n",
            "Epoch 72/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8415 - acc: 0.7487 - val_loss: 0.8729 - val_acc: 0.7500\n",
            "Epoch 73/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8729 - acc: 0.7357 - val_loss: 0.8619 - val_acc: 0.7500\n",
            "Epoch 74/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8883 - acc: 0.7239"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8850 - acc: 0.7266 - val_loss: 0.8668 - val_acc: 0.7500\n",
            "Epoch 75/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8768 - acc: 0.7318 - val_loss: 0.8636 - val_acc: 0.7500\n",
            "Epoch 76/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8172 - acc: 0.7552 - val_loss: 0.8607 - val_acc: 0.7500\n",
            "Epoch 77/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9073 - acc: 0.7187 - val_loss: 0.8710 - val_acc: 0.7500\n",
            "Epoch 78/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8140 - acc: 0.7729"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8249 - acc: 0.7617 - val_loss: 0.8609 - val_acc: 0.7500\n",
            "Epoch 79/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.9496 - acc: 0.7122 - val_loss: 0.8627 - val_acc: 0.7500\n",
            "Epoch 80/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8366 - acc: 0.7487 - val_loss: 0.9017 - val_acc: 0.7500\n",
            "Epoch 81/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8619 - acc: 0.7305 - val_loss: 0.8643 - val_acc: 0.7500\n",
            "Epoch 82/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.9135 - acc: 0.7075"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.9004 - acc: 0.7148 - val_loss: 0.8716 - val_acc: 0.7500\n",
            "Epoch 83/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8745 - acc: 0.7422 - val_loss: 0.8570 - val_acc: 0.7500\n",
            "Epoch 84/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8733 - acc: 0.7344 - val_loss: 0.8611 - val_acc: 0.7500\n",
            "Epoch 85/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.8329 - acc: 0.7409 - val_loss: 0.8638 - val_acc: 0.7500\n",
            "Epoch 86/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8785 - acc: 0.7288"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8702 - acc: 0.7292 - val_loss: 0.8673 - val_acc: 0.7500\n",
            "Epoch 87/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8722 - acc: 0.7344 - val_loss: 0.8571 - val_acc: 0.7500\n",
            "Epoch 88/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.8859 - acc: 0.7253 - val_loss: 0.8993 - val_acc: 0.7500\n",
            "Epoch 89/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.7996 - acc: 0.7552 - val_loss: 0.8925 - val_acc: 0.7500\n",
            "Epoch 90/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.8931 - acc: 0.7353"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8936 - acc: 0.7292 - val_loss: 0.8603 - val_acc: 0.7500\n",
            "Epoch 91/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.8769 - acc: 0.7396 - val_loss: 0.8604 - val_acc: 0.7500\n",
            "Epoch 92/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.8165 - acc: 0.7487 - val_loss: 0.8705 - val_acc: 0.7500\n",
            "Epoch 93/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.8988 - acc: 0.7201 - val_loss: 0.8915 - val_acc: 0.7500\n",
            "Epoch 94/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.9121 - acc: 0.7075"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 68s 1s/step - loss: 0.8810 - acc: 0.7201 - val_loss: 0.8972 - val_acc: 0.7500\n",
            "Epoch 95/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.8409 - acc: 0.7435 - val_loss: 0.8760 - val_acc: 0.7500\n",
            "Epoch 96/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8252 - acc: 0.7526 - val_loss: 0.8872 - val_acc: 0.7500\n",
            "Epoch 97/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.8819 - acc: 0.7305 - val_loss: 0.8801 - val_acc: 0.7500\n",
            "Epoch 98/1000\n",
            "51/64 [======================>.......] - ETA: 10s - loss: 0.9027 - acc: 0.7173"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8875 - acc: 0.7240 - val_loss: 0.8893 - val_acc: 0.7500\n",
            "Epoch 99/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8578 - acc: 0.7292 - val_loss: 0.8677 - val_acc: 0.7500\n",
            "Epoch 100/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.7991 - acc: 0.7513 - val_loss: 0.9159 - val_acc: 0.7500\n",
            "Epoch 101/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8868 - acc: 0.7305 - val_loss: 0.9190 - val_acc: 0.7500\n",
            "Epoch 102/1000\n",
            "50/64 [======================>.......] - ETA: 11s - loss: 0.8962 - acc: 0.7267"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.8733 - acc: 0.7331 - val_loss: 0.8583 - val_acc: 0.7500\n",
            "Epoch 103/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8361 - acc: 0.7448 - val_loss: 0.9608 - val_acc: 0.7500\n",
            "Epoch 104/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8568 - acc: 0.7383 - val_loss: 0.9262 - val_acc: 0.7500\n",
            "Epoch 105/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8623 - acc: 0.7292 - val_loss: 0.9410 - val_acc: 0.7500\n",
            "Epoch 106/1000\n",
            "50/64 [======================>.......] - ETA: 11s - loss: 0.9532 - acc: 0.6900"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 69s 1s/step - loss: 0.9493 - acc: 0.6927 - val_loss: 0.9390 - val_acc: 0.7500\n",
            "Epoch 107/1000\n",
            "64/64 [==============================] - 69s 1s/step - loss: 0.8498 - acc: 0.7383 - val_loss: 0.9757 - val_acc: 0.7500\n",
            "Epoch 108/1000\n",
            "64/64 [==============================] - 68s 1s/step - loss: 0.8204 - acc: 0.7448 - val_loss: 0.8907 - val_acc: 0.7500\n",
            "Epoch 109/1000\n",
            " 9/64 [===>..........................] - ETA: 45s - loss: 0.7410 - acc: 0.7685"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-973de056bb6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Y6Y49IsjzCb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52724f5e-d57c-4fd8-b8c2-9e21732400cd"
      },
      "cell_type": "code",
      "source": [
        "  !ls  train"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat  dog\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lcoXqRB1NY5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "86b9e3a7-5812-4888-da2d-0d378ef3bf40"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-135e74fd527b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5DcQ8I1S0aV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16016
        },
        "outputId": "b6171eff-3d85-46c5-9f7f-5e01a50a01fd"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!pip install -U -q PyDrive\n",
            "from pydrive.auth import GoogleAuth\n",
            "from pydrive.drive import GoogleDrive\n",
            "from google.colab import auth\n",
            "from oauth2client.client import GoogleCredentials\n",
            "\n",
            "# 1. Authenticate and create the PyDrive client.\n",
            "auth.authenticate_user()\n",
            "gauth = GoogleAuth()\n",
            "gauth.credentials = GoogleCredentials.get_application_default()\n",
            "drive = GoogleDrive(gauth)\n",
            "from google.colab import files\n",
            "uploaded = files.upload()\n",
            "!pip install -U -q PyDrive ## you will have install for every colab session\n",
            "!mkdir /content/.kaggle\n",
            "#!mv /content/.kaggle kaggle.json\n",
            "#!ls\n",
            "#!chmod 600 ~ kaggle.json\n",
            "!mv kaggle.json /content/.kaggle\n",
            "\n",
            "!ls /content/.kaggle/\n",
            "!chmod 600 ~ /content/.kaggle/kaggle.json\n",
            "!pip install kaggle\n",
            "!kaggle competitions list -s health\n",
            "!kaggle competitions download -c diabetic-retinopathy-detection -p datalab\n",
            "!apt-get install p7zip-full\n",
            "!7z x datalab/train.zip.001\n",
            "!ls train | head -4\n",
            "import numpy as np # linear algebra\n",
            "import pandas as pd \n",
            "import os\n",
            "!unzip datalab/trainLabels.csv.zip\n",
            "trainLabels = pd.read_csv(\"trainLabels.csv\")\n",
            "trainLabels.head()\n",
            "!mkdir output\n",
            "!mkdir output/train\n",
            "!mkdir output/val\n",
            "%%capture\n",
            "import os\n",
            "\n",
            "dir_path = \"./train\"\n",
            "output_path = \"./output/train\"\n",
            "\n",
            "if not os.path.exists(output_path):\n",
            "    os.mkdir(output_path)\n",
            "\n",
            "for file_name in listing_test:\n",
            "    if \"jpeg\" in file_name:\n",
            "      if str(file_name).split(\"_\")[1]==\"right.jpeg\":\n",
            "        path = \"{}/{}\".format(dir_path, file_name)\n",
            "        output = \"{}/{}\".format(output_path, file_name)\n",
            "        new_img = preprocess_image(path)\n",
            "        cv.imwrite(output, new_img)\n",
            "%%capture\n",
            "import os\n",
            "\n",
            "dir_path = \"./train\"\n",
            "output_path = \"./output/val\"\n",
            "\n",
            "if not os.path.exists(output_path):\n",
            "    os.mkdir(output_path)\n",
            "\n",
            "for file_name in listing_val:\n",
            "    if \"jpeg\" in file_name:\n",
            "      if str(file_name).split(\"_\")[1]==\"right.jpeg\":\n",
            "        path = \"{}/{}\".format(dir_path, file_name)\n",
            "        output = \"{}/{}\".format(output_path, file_name)\n",
            "        new_img = preprocess_image(path)\n",
            "        cv.imwrite(output, new_img)\n",
            "listing = os.listdir(\"train\") \n",
            "len(listing)\n",
            "listing_test=listing[:5000]\n",
            "listing_val=listing[5000:7000]\n",
            "\"\"\"\n",
            "Created on Thu Apr 19 23:09:09 2018\n",
            "\n",
            "@author: abhik\n",
            "\"\"\"\n",
            "\n",
            "import cv2 as cv\n",
            "import numpy as np\n",
            "import math\n",
            "\n",
            "# Standard resolution of images after processing.\n",
            "STD_RES = 756\n",
            "\n",
            "# Thresholding parameter.\n",
            "THRESH = 30  # For edge detection\n",
            "\n",
            "# Canny edge detection parameters.\n",
            "LOW_THRESH = 0\n",
            "MAX_THRESH = 255\n",
            "KERNEL = 3\n",
            "\n",
            "# Hough Circle Transform parameters.\n",
            "DP = 2  # Inverse accumulator ratio.\n",
            "MD = STD_RES  # Minimum distance between circles.\n",
            "P1 = 140\n",
            "P2 = 30\n",
            "MIN_R = int(STD_RES * 0.4)\n",
            "MAX_R = STD_RES\n",
            "\n",
            "# Blob detection parameters (for notch detection).\n",
            "BLOB_PARAMS = cv.SimpleBlobDetector_Params()\n",
            "BLOB_PARAMS.minThreshold = 0.0\n",
            "BLOB_PARAMS.maxThreshold = THRESH\n",
            "BLOB_PARAMS.thresholdStep = THRESH / 2\n",
            "BLOB_PARAMS.filterByArea = False\n",
            "BLOB_PARAMS.filterByColor = False\n",
            "BLOB_PARAMS.filterByConvexity = False\n",
            "BLOB_PARAMS.filterByInertia = True\n",
            "BLOB_PARAMS.minInertiaRatio = 0.05\n",
            "BLOB_PARAMS.maxInertiaRatio = 1\n",
            "\n",
            "\n",
            "def preprocess_image(path):\n",
            "    \"\"\"\n",
            "    Loads an image, converts to grayscale, flips the image if necessary based\n",
            "    on which eye it is and if there is a notch present, and equalizes the\n",
            "    image's histogram.\n",
            "    :param str path: Path to an image.\n",
            "    :rtype: numpy.ndarray\n",
            "    \"\"\"\n",
            "    # Loading the image also converts it to grayscale.\n",
            "    img = load_image(path)\n",
            "    img_thresh = threshold(img)\n",
            "\n",
            "    # Two-part notch-detection. Notch could be in upper-right quadrant, or it\n",
            "    # could be in the bottom-right quadrant. Try the upper-right corner first -\n",
            "    # if it's not there, try the bottom-right. If still no notch is detected,\n",
            "    # assume there is no notch present and do no inversion.\n",
            "    if detect_notch(img, img_thresh):\n",
            "        cv.flip(img, -1, img)\n",
            "        print(\"Notch detected in image {}.\".format(path.split('/')[-1]))\n",
            "    else:\n",
            "        vert_flip = cv.flip(img, 0)\n",
            "        vert_flip_thresh = cv.flip(img_thresh, 0)\n",
            "\n",
            "        if detect_notch(vert_flip, vert_flip_thresh):\n",
            "            cv.flip(img, -1, img)\n",
            "            print(\"Notch detected in image {}.\".format(path.split('/')[-1]))\n",
            "\n",
            "    # Examine the file name and flip the eye horizontally if it's a left eye.\n",
            "    if \"left\" in path:\n",
            "        cv.flip(img, 1, img)\n",
            "\n",
            "    # Finally, equalize the image.\n",
            "    cv.equalizeHist(img, img)\n",
            "\n",
            "    return img\n",
            "\n",
            "\n",
            "def load_image(path, grayscale=True, equalize=False, resize=True):\n",
            "    \"\"\"\n",
            "    Loads an image, transforms it to grayscale, and resizes it. Optionally\n",
            "    equalizes the image's histogram. Equalization seems to play poorly with\n",
            "    preprocessing however, so by default it is turned off.\n",
            "    :param path: Path to the image file.\n",
            "    :param grayscale: Flag for converting image to grayscale.\n",
            "    :param equalize: Flag for equalizing the image's histogram.\n",
            "    :param resize: Flag for resizing the image to standard resolution.\n",
            "    :rtype: np.ndarray\n",
            "    \"\"\"\n",
            "\n",
            "    img_in = cv.imread(path, cv.IMREAD_GRAYSCALE if grayscale else -1)\n",
            "    if equalize:\n",
            "        cv.equalizeHist(img_in, img_in)\n",
            "\n",
            "    if resize:\n",
            "        img_in = bb_resize(img_in, threshold(img_in))\n",
            "\n",
            "    return img_in\n",
            "\n",
            "\n",
            "def threshold(img):\n",
            "    \"\"\" Thresholds image according to global parameter. \"\"\"\n",
            "    _, output = cv.threshold(img, THRESH, 255, cv.THRESH_BINARY)\n",
            "    return output\n",
            "\n",
            "\n",
            "def hough_circles(img):\n",
            "    \"\"\"\n",
            "    Apply Hough Circle Transform using global parameters and returns data in\n",
            "    a nice list-of-tuples format. If no circles are found, the empty list is\n",
            "    returned.\n",
            "    :param np.ndarray img: The image to search for circles.\n",
            "    :returns: List of tuples of the form (x, y, radius)\n",
            "    :rtype: list[(int, int, float)]\n",
            "    \"\"\"\n",
            "    global DP, MD, P1, P2, MIN_R, MAX_R\n",
            "    img = img.copy()\n",
            "\n",
            "    # Black out the NW, SW, and SE quadrants to force Hough detection to align\n",
            "    # to notch edge. This is done to hopefully reduce the amount of \"edge\" that\n",
            "    # is left over after subtraction.\n",
            "    h, w = img.shape\n",
            "    half_h, half_w = (int(h / 2), int(w / 2))\n",
            "    cv.rectangle(img, (0, 0), (half_w, h),\n",
            "                 (0, 0, 0), thickness=cv.FILLED)\n",
            "    cv.rectangle(img, (0, h), (w, half_h),\n",
            "                 (0, 0, 0), thickness=cv.FILLED)\n",
            "\n",
            "    circles = cv.HoughCircles(img, cv.HOUGH_GRADIENT, DP, MD,\n",
            "                              param1=P1, param2=P2,\n",
            "                              minRadius=MIN_R, maxRadius=MAX_R)\n",
            "\n",
            "    output = []\n",
            "    if circles is not None:\n",
            "        circles = circles[0]  # Why are tuples buried like this? Bug?\n",
            "        for c in circles[0:]:\n",
            "            output.append((c[0], c[1], c[2]))\n",
            "\n",
            "    return output\n",
            "\n",
            "\n",
            "def bb_resize(img, img_thresh):\n",
            "    \"\"\"\n",
            "    Resizes an image using bounding boxes. This is done by thresholding the\n",
            "    image and then calculating its bounding box. The shorter dimension of the\n",
            "    bounding box is then expanded (with black pixels) to make the bounding box\n",
            "    square. The pixels in the bounding box are moved to a new image, which is\n",
            "    then resized to a standard resolution.\n",
            "    This effect of this process should be that any eyeball image is roughly\n",
            "    centered at the same position and about the same size. This is important for\n",
            "    notch detection so that a small square can be placed approximately over\n",
            "    where the notch should be in a standardized image.\n",
            "    \"\"\"\n",
            "    x, y, w, h = cv.boundingRect(img_thresh)\n",
            "\n",
            "    # If no bounding rectangle was able to be formed, then the image is\n",
            "    # probably completely unusable. Simply resize to standard resolution and\n",
            "    # move on.\n",
            "    if (w == 0) or (h == 0):\n",
            "        return cv.resize(img, (STD_RES, STD_RES), interpolation=cv.INTER_AREA)\n",
            "\n",
            "    # Destination canvas is square, length of max dimension of the bb.\n",
            "    max_wh = max(w, h)\n",
            "    img_expand = np.zeros((max_wh, max_wh), dtype=np.uint8)\n",
            "\n",
            "    # Copy the bounding box (region of interest) into the center of the\n",
            "    # destination canvas. This will produce black bars on the short side.\n",
            "    diff_w = max_wh - w\n",
            "    diff_h = max_wh - h\n",
            "    half_dw = int(math.floor(diff_w / 2.0))\n",
            "    half_dh = int(math.floor(diff_h / 2.0))\n",
            "    roi = img[y:y + h, x:x + w]\n",
            "    img_expand[half_dh:(half_dh + h), half_dw:(half_dw + w)] = roi\n",
            "\n",
            "    # Resize to our standard resolution.\n",
            "    return cv.resize(img_expand, (STD_RES, STD_RES), interpolation=cv.INTER_AREA)\n",
            "\n",
            "\n",
            "def detect_notch(img, img_thresh):\n",
            "    \"\"\"\n",
            "    Detects if a notch is present in the image, and if so, returns True.\n",
            "    First, the Hough Circle Transform is applied to find a circle corresponding\n",
            "    to the entire eyeball. This circle is subtracted from the thresholded\n",
            "    image of the eyeball. Ideally what is left at this point will be either\n",
            "    a notch, or nothing. Since we will likely pick up \"shreds\" left from the\n",
            "    edges of the subtraction, we contract and dilate at this point to remove\n",
            "    leftovers.\n",
            "    A region of interest is positioned over where notches appear usually,\n",
            "    which is at about the 45 degree mark on the eyeball in the NE quadrant.\n",
            "    Blob detection is run over this ROI. If a blob is detected, it is assumed\n",
            "    that the blob is a notch, and the function can return True.\n",
            "    \"\"\"\n",
            "    circles = hough_circles(img)\n",
            "\n",
            "    # Paint out the first circle detected. Assume that only one circle was\n",
            "    # detected for whole image. If no circles are detected, fail fast and just\n",
            "    # return false.\n",
            "    if circles:\n",
            "        x, y, r = circles[0]\n",
            "        cv.circle(img_thresh, (x, y), r, (0, 0, 0), cv.FILLED)\n",
            "    else:\n",
            "        return False\n",
            "\n",
            "    # Erode what's left to try and remove edges.\n",
            "    img_thresh = cv.erode(img_thresh, np.ones((3, 3), np.uint8))\n",
            "    img_thresh = cv.dilate(img_thresh, np.ones((3, 3), np.uint8))\n",
            "\n",
            "    # Extract a region of interest that is very likely to contain the notch if\n",
            "    # one is present in the image. This corresponds to a small square at about\n",
            "    # the 45 degree mark on the eyeball. Some notches are slightly lower than\n",
            "    # this, so the ROI should be large enough to capture many notch positions.\n",
            "    ratio = 1.0 / 4.0\n",
            "    roi_size = img_thresh.shape[0] * ratio\n",
            "    half_rs = roi_size / 2.0\n",
            "\n",
            "    # Do a little trig to find cartesian coordinates of 45 degrees point.\n",
            "    radius = img_thresh.shape[0] / 2.0\n",
            "    angle = math.pi / 4.0\n",
            "    side = radius * math.sin(angle)\n",
            "\n",
            "    # Get the damned ROI.\n",
            "    x, y = (int(radius + side - half_rs), int(radius - side - half_rs))\n",
            "    roi = img_thresh[y:int(y + roi_size), x:int(x + roi_size)]\n",
            "\n",
            "    # Run blob detection on what's left.\n",
            "    sbd = cv.SimpleBlobDetector_create(BLOB_PARAMS)\n",
            "    keypoints = sbd.detect(roi)\n",
            "\n",
            "    # If keypoints were found, then we assume that a notch was detected.\n",
            "    return bool(keypoints)\n",
            "\n",
            "\n",
            "def draw_hough_circles(img, circles):\n",
            "    \"\"\"\n",
            "    Creates new image from img with circles drawn over it. Will convert the\n",
            "    output image to RGB space.\n",
            "    :param np.ndarray img:\n",
            "    :param list[(int, int, float)] circles: Detected circles.\n",
            "    :rtype: np.ndarray\n",
            "    \"\"\"\n",
            "    if circles:\n",
            "        output = cv.cvtColor(img.copy(), cv.COLOR_GRAY2RGB)\n",
            "        for c in circles:\n",
            "            x, y, r = c\n",
            "            cv.circle(output, (x, y), r, (0, 0, 255), 2)\n",
            "    else:\n",
            "        output = img\n",
            "\n",
            "    return output\n",
            "\n",
            "\n",
            "def experiment_threshold(path):\n",
            "    \"\"\"\n",
            "    Launches experiment window for thresholding.\n",
            "    :param str path: Path to the experiment image file.\n",
            "    \"\"\"\n",
            "    img = load_image(path)\n",
            "    _, thresh_img = cv.threshold(img, THRESH, 255, cv.THRESH_BINARY)\n",
            "\n",
            "    # Image windows for this experiment.\n",
            "    t_window = \"Threshold Experiment\"\n",
            "    o_window = \"Original Image\"\n",
            "    cv.namedWindow(t_window, cv.WINDOW_AUTOSIZE)\n",
            "    cv.namedWindow(o_window, cv.WINDOW_AUTOSIZE)\n",
            "\n",
            "    # Callback for parameter slider (instantiated afterward).\n",
            "    def thresh_callback(pos):\n",
            "        #cv.threshold(img, pos, 255, cv.THRESH_BINARY, dst=thresh_img)\n",
            "        #cv.imshow(t_window, thresh_img)\n",
            "        return\n",
            "\n",
            "    # Create the experiment and original image windows.\n",
            "    #cv.createTrackbar(\"Threshold\", t_window, THRESH, 255, thresh_callback)\n",
            "    #cv.imshow(t_window, thresh_img)\n",
            "    #cv.imshow(o_window, img)\n",
            "    #cv.waitKey(0)\n",
            "    return\n",
            "\n",
            "\n",
            "def experiment_hough(path):\n",
            "    \"\"\"\n",
            "    Launches experiment window for the Hough Circle Transformation.\n",
            "    :param str path: Path to the experiment image file.\n",
            "    \"\"\"\n",
            "    # Threshold the image first to get rid of pesky noise.\n",
            "    img = load_image(path)\n",
            "\n",
            "    # Image windows for this experiment.\n",
            "    t_window = \"Hough Circle Transform Experiment\"\n",
            "    cv.namedWindow(t_window, cv.WINDOW_AUTOSIZE)\n",
            "\n",
            "    # Callbacks for parameter sliders (instantiated afterward).\n",
            "    def dp_callback(pos):\n",
            "        global DP\n",
            "        DP = pos\n",
            "        #cv.imshow(t_window, draw_hough_circles(img, hough_circles(img)))\n",
            "        return\n",
            "\n",
            "    def p1_callback(pos):\n",
            "        global P1\n",
            "        P1 = pos\n",
            "        #cv.imshow(t_window, draw_hough_circles(img, hough_circles(img)))\n",
            "        return\n",
            "\n",
            "    def p2_callback(pos):\n",
            "        global P2\n",
            "        P2 = pos\n",
            "        #cv.imshow(t_window, draw_hough_circles(img, hough_circles(img)))\n",
            "        return\n",
            "\n",
            "    # Create the experiment and original image windows.\n",
            "    #cv.createTrackbar(\"DP\", t_window, DP, 10, dp_callback)\n",
            "    #cv.createTrackbar(\"P1\", t_window, P1, 255, p1_callback)\n",
            "    #cv.createTrackbar(\"P2\", t_window, P2, 255, p2_callback)\n",
            "    #cv.imshow(t_window, draw_hough_circles(img, hough_circles(img)))\n",
            "    #cv.waitKey(0)\n",
            "\n",
            "\n",
            "def experiment_edge_detect(path):\n",
            "    img = load_image(path)\n",
            "    img = threshold(img)\n",
            "    edges = cv.Canny(img, LOW_THRESH, MAX_THRESH, apertureSize=KERNEL)\n",
            "\n",
            "    # Image windows for this experiment.\n",
            "    t_window = \"Canny Edge Detect Experiment\"\n",
            "    cv.namedWindow(t_window, cv.WINDOW_AUTOSIZE)\n",
            "\n",
            "    # Callbacks for parameter sliders (instantiated afterward).\n",
            "    def low_thresh_callback(pos):\n",
            "        global LOW_THRESH\n",
            "        LOW_THRESH = pos\n",
            "        edges = cv.Canny(img, LOW_THRESH, MAX_THRESH, apertureSize=KERNEL)\n",
            "        cv.imshow(t_window, edges)\n",
            "        return\n",
            "\n",
            "    #cv.createTrackbar(\"Low Threshold\", t_window, LOW_THRESH, 255, low_thresh_callback)\n",
            "    #cv.imshow(t_window, edges)\n",
            "    #cv.waitKey(0)\n",
            "\n",
            "\n",
            "def experiment_notch_detection(path):\n",
            "    \"\"\" Notch detection via circle subtraction and blob detection. \"\"\"\n",
            "    # Get thresholded image and hough circles.\n",
            "    img = load_image(path)\n",
            "    img_thresh = threshold(img)\n",
            "    circles = hough_circles(img)\n",
            "\n",
            "    # Paint out the first circle detected. Assume that only one circle was\n",
            "    # detected for whole image.\n",
            "    x, y, r = circles[0]\n",
            "    cv.circle(img_thresh, (x, y), r, (0, 0, 0), cv.FILLED)\n",
            "\n",
            "    # Erode what's left to try and remove edges.\n",
            "    img_thresh = cv.erode(img_thresh, np.ones((3, 3), np.uint8))\n",
            "    img_thresh = cv.dilate(img_thresh, np.ones((3, 3), np.uint8))\n",
            "\n",
            "    # Extract a region of interest that is very likely to contain the notch if\n",
            "    # one is present in the image. This corresponds to a small square at about\n",
            "    # the 45 degree mark on the eyeball. Some notches are slightly lower than\n",
            "    # this, so the ROI should be large enough to capture many notch positions.\n",
            "    ratio = 1.0 / 4.0\n",
            "    roi_size = img_thresh.shape[0] * ratio\n",
            "    half_rs = roi_size / 2.0\n",
            "\n",
            "    # Do a little trig to find cartesian coordinates of 45 degrees point.\n",
            "    radius = img_thresh.shape[0] / 2.0\n",
            "    angle = math.pi / 4.0\n",
            "    side = radius * math.sin(angle)\n",
            "\n",
            "    # Get the damned ROI.\n",
            "    x, y = (int(radius + side - half_rs), int(radius - side - half_rs))\n",
            "    cv.rectangle(img, (x, y), (x + int(roi_size), y + int(roi_size)), (255, 255, 255))\n",
            "    roi = img_thresh[y:int(y + roi_size), x:int(x + roi_size)]\n",
            "\n",
            "    # Run blob detection on what's left.\n",
            "    # Set up the detector with default parameters.\n",
            "    blob_params = cv.SimpleBlobDetector_Params()\n",
            "    blob_params.minThreshold = 0.0\n",
            "    blob_params.maxThreshold = THRESH\n",
            "    blob_params.thresholdStep = THRESH / 2\n",
            "    blob_params.filterByArea = False\n",
            "    blob_params.filterByColor = False\n",
            "    blob_params.filterByConvexity = False\n",
            "    blob_params.filterByInertia = True\n",
            "    blob_params.minInertiaRatio = 0.05\n",
            "    blob_params.maxInertiaRatio = 1\n",
            "    sbd = cv.SimpleBlobDetector_create(blob_params)\n",
            "\n",
            "    # Detect blobs.\n",
            "    keypoints = sbd.detect(roi)\n",
            "\n",
            "    # Draw circles around any detected blobs.\n",
            "    # cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle\n",
            "    # corresponds to the size of blob\n",
            "    roi = cv.drawKeypoints(roi, keypoints, np.array([]),\n",
            "                           (0, 0, 255),\n",
            "                           cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
            "\n",
            "    # Image windows for this experiment.\n",
            "    o_window = \"Original Image\"\n",
            "    t_window = \"Thresholded, Subtracted, Blob-Detected\"\n",
            "    cv.namedWindow(o_window, cv.WINDOW_AUTOSIZE)\n",
            "    cv.namedWindow(t_window, cv.WINDOW_AUTOSIZE)\n",
            "    cv.imshow(o_window, img)\n",
            "    cv.imshow(t_window, roi)\n",
            "    cv.waitKey(0)\n",
            "    return\n",
            "\n",
            "\n",
            "def experiment_bounding_box(path):\n",
            "    \"\"\" Bounding box resizing experiment. \"\"\"\n",
            "\n",
            "    # Calculate initial bounding box via thresholded image.\n",
            "    img = load_image(path, resize=False)\n",
            "    img_thresh = threshold(img)\n",
            "    x, y, w, h = cv.boundingRect(img_thresh)\n",
            "\n",
            "    max_wh = max(w, h)\n",
            "    diff_w = max_wh - w\n",
            "    diff_h = max_wh - h\n",
            "    half_dw = int(math.floor(diff_w / 2.0))\n",
            "    half_dh = int(math.floor(diff_h / 2.0))\n",
            "    img_expand = np.zeros((max_wh, max_wh), dtype=np.uint8)\n",
            "    roi = img[y:y + h, x:x + w]\n",
            "    img_expand[half_dh:(half_dh + h), half_dw:(half_dw + w)] = roi\n",
            "\n",
            "    img_resize = cv.resize(img_expand,\n",
            "                           (STD_RES, STD_RES),\n",
            "                           interpolation=cv.INTER_AREA)\n",
            "\n",
            "    r_window = \"Resized Image\"\n",
            "    #cv.namedWindow(r_window, cv.WINDOW_AUTOSIZE)\n",
            "    #cv.imshow(r_window, img_resize)\n",
            "    #cv.waitKey(0)\n",
            "!mkdir output\n",
            "!mkdir output/train\n",
            "!mkdir output/val\n",
            "%%capture\n",
            "import os\n",
            "\n",
            "dir_path = \"./train\"\n",
            "output_path = \"./output/train\"\n",
            "\n",
            "if not os.path.exists(output_path):\n",
            "    os.mkdir(output_path)\n",
            "\n",
            "for file_name in listing_test:\n",
            "    if \"jpeg\" in file_name:\n",
            "      if str(file_name).split(\"_\")[1]==\"right.jpeg\":\n",
            "        path = \"{}/{}\".format(dir_path, file_name)\n",
            "        output = \"{}/{}\".format(output_path, file_name)\n",
            "        new_img = preprocess_image(path)\n",
            "        cv.imwrite(output, new_img)\n",
            "%%capture\n",
            "import os\n",
            "\n",
            "dir_path = \"./train\"\n",
            "output_path = \"./output/val\"\n",
            "\n",
            "if not os.path.exists(output_path):\n",
            "    os.mkdir(output_path)\n",
            "\n",
            "for file_name in listing_val:\n",
            "    if \"jpeg\" in file_name:\n",
            "      if str(file_name).split(\"_\")[1]==\"right.jpeg\":\n",
            "        path = \"{}/{}\".format(dir_path, file_name)\n",
            "        output = \"{}/{}\".format(output_path, file_name)\n",
            "        new_img = preprocess_image(path)\n",
            "        cv.imwrite(output, new_img)\n",
            "!ls output/val -1 | wc -l\n",
            "!ls output/train -1 | wc -l\n",
            "!mkdir output/train/0\n",
            "!mkdir output/train/1\n",
            "!mkdir output/train/2\n",
            "!mkdir output/train/3\n",
            "!mkdir output/train/4\n",
            "!mkdir output/val/0\n",
            "!mkdir output/val/1\n",
            "!mkdir output/val/2\n",
            "!mkdir output/val/3\n",
            "!mkdir output/val/4\n",
            "listing_train = os.listdir(\"output/train\")\n",
            "listing_val = os.listdir(\"output/val\")\n",
            "file=listing_train[0]\n",
            "base = os.path.basename(\"output/\" + file)\n",
            "print( os.path.splitext(file)[0])\n",
            "from PIL import Image\n",
            "\n",
            "base_dir = \"output/val/\"\n",
            "\n",
            "for file in listing_val:\n",
            "  try:\n",
            "    fileName = os.path.splitext(file)[0]\n",
            "    folder_name = trainLabels.loc[trainLabels.image==fileName, 'level'].values[0]  \n",
            "    os.rename(base_dir + file, base_dir + str(folder_name) + \"/\" + file )\n",
            "  except:\n",
            "    pass\n",
            "from PIL import Image\n",
            "\n",
            "base_dir = \"output/train/\"\n",
            "\n",
            "for file in listing_train:\n",
            "  try:\n",
            "    fileName = os.path.splitext(file)[0]\n",
            "    folder_name = trainLabels.loc[trainLabels.image==fileName, 'level'].values[0]  \n",
            "    os.rename(base_dir + file, base_dir + str(folder_name) + \"/\" + file )\n",
            "  except:\n",
            "    pass\n",
            "from keras.applications import VGG16\n",
            " \n",
            "conv_base = VGG16(weights='imagenet',\n",
            "                  include_top=False,\n",
            "                  input_shape=(224, 224, 3))\n",
            "batch_size = 12\n",
            "from keras.preprocessing.image import ImageDataGenerator\n",
            "\n",
            "data_gen_args = dict(rescale=1./255,samplewise_std_normalization=True)\n",
            "\n",
            "datagen = ImageDataGenerator(**data_gen_args)\n",
            "\n",
            " \n",
            "\n",
            "train_generator = datagen.flow_from_directory(\n",
            "    \"./output/train\",\n",
            "    target_size=(750, 750),\n",
            "    batch_size=batch_size,\n",
            "    class_mode='categorical')\n",
            "from keras.preprocessing.image import ImageDataGenerator\n",
            "\n",
            "data_gen_args = dict(rescale=1./255,samplewise_std_normalization=True)\n",
            "\n",
            "datagen = ImageDataGenerator(**data_gen_args)\n",
            "\n",
            " \n",
            "\n",
            "val_generator = datagen.flow_from_directory(\n",
            "    \"./output/val\",\n",
            "    target_size=(750, 750),\n",
            "    batch_size=batch_size,\n",
            "    class_mode='categorical')\n",
            "nb_filters = 30\n",
            "# size of pooling area for max pooling\n",
            "nb_pool = 2\n",
            "# convolution kernel size\n",
            "nb_conv = 4\n",
            "\n",
            "\n",
            "# number of output classes\n",
            "nb_classes = 5\n",
            "# number of epochs to train\n",
            "nb_epoch = 64\n",
            "\n",
            "img_rows, img_cols = 224,224\n",
            "from keras.models import Sequential\n",
            "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
            "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
            "from keras.optimizers import SGD,RMSprop,adam\n",
            "import keras\n",
            "\n",
            "adam = keras.optimizers.Adam(lr=3e-03, beta_1=0.9, beta_2=0.9999, epsilon=None, decay=0.00001, amsgrad=False)\n",
            "\n",
            "model = Sequential()\n",
            "\n",
            "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
            "                        border_mode='valid',\n",
            "                        input_shape=(img_cols, img_rows, 3)))\n",
            "convout1 = Activation('relu')\n",
            "model.add(convout1)\n",
            "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
            "model.add(Dropout(0.5))\n",
            "convout2 = Activation('relu')\n",
            "model.add(convout2)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+1, nb_pool+1)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "convout3 = Activation('relu')\n",
            "model.add(convout3)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "convout4 = Activation('relu')\n",
            "model.add(convout4)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "model.add(Flatten())\n",
            "model.add(Dense(680))\n",
            "model.add(Activation('relu'))\n",
            "model.add(Dense(128))\n",
            "model.add(Activation('relu'))\n",
            "model.add(Dropout(0.5))\n",
            "model.add(Dense(5))\n",
            "model.add(Activation('softmax'))\n",
            "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
            "\n",
            "from keras import models\n",
            "from keras import layers\n",
            "from keras import optimizers\n",
            "\n",
            "model = models.Sequential()\n",
            "model.add(layers.Dense(256, activation='relu', input_dim=7 * 7 * 512))\n",
            "model.add(layers.Dropout(0.5))\n",
            "model.add(layers.Dense(1, activation='sigmoid'))\n",
            "model.compile(optimizer=optimizers.RMSprop(lr=2e-4),\n",
            "              loss='binary_crossentropy',\n",
            "              metrics=['acc'])\n",
            "model.summary()\n",
            "from keras.models import Sequential\n",
            "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
            "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
            "from keras.optimizers import SGD,RMSprop,adam\n",
            "import keras\n",
            "\n",
            "adam = keras.optimizers.Adam(lr=3e-03, beta_1=0.9, beta_2=0.9999, epsilon=None, decay=0.00001, amsgrad=False)\n",
            "\n",
            "model = Sequential()\n",
            "\n",
            "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
            "                        border_mode='valid',\n",
            "                        input_shape=(img_cols, img_rows, 3)))\n",
            "convout1 = Activation('relu')\n",
            "model.add(convout1)\n",
            "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
            "model.add(Dropout(0.5))\n",
            "convout2 = Activation('relu')\n",
            "model.add(convout2)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+1, nb_pool+1)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "convout3 = Activation('relu')\n",
            "model.add(convout3)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "convout4 = Activation('relu')\n",
            "model.add(convout4)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "model.add(Flatten())\n",
            "model.add(Dense(680))\n",
            "model.add(Activation('relu'))\n",
            "model.add(Dense(128))\n",
            "model.add(Activation('relu'))\n",
            "model.add(Dropout(0.5))\n",
            "model.add(Dense(5))\n",
            "model.add(Activation('softmax'))\n",
            "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
            "model.summary()\n",
            "hist = model.fit_generator(train_generator, steps_per_epoch=64, epochs=1000, validation_data=val_generator, validation_steps=50)\n",
            "hist = model.fit_generator(train_generator, steps_per_epoch=64, epochs=1000, validation_data=val_generator, validation_steps=50)\n",
            "nb_filters = 30\n",
            "# size of pooling area for max pooling\n",
            "nb_pool = 2\n",
            "# convolution kernel size\n",
            "nb_conv = 4\n",
            "\n",
            "\n",
            "# number of output classes\n",
            "nb_classes = 5\n",
            "# number of epochs to train\n",
            "nb_epoch = 64\n",
            "\n",
            "img_rows, img_cols = 750,750\n",
            "from keras.models import Sequential\n",
            "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
            "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
            "from keras.optimizers import SGD,RMSprop,adam\n",
            "import keras\n",
            "\n",
            "adam = keras.optimizers.Adam(lr=3e-03, beta_1=0.9, beta_2=0.9999, epsilon=None, decay=0.00001, amsgrad=False)\n",
            "\n",
            "model = Sequential()\n",
            "\n",
            "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
            "                        border_mode='valid',\n",
            "                        input_shape=(img_cols, img_rows, 3)))\n",
            "convout1 = Activation('relu')\n",
            "model.add(convout1)\n",
            "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
            "model.add(Dropout(0.5))\n",
            "convout2 = Activation('relu')\n",
            "model.add(convout2)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+1, nb_pool+1)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "convout3 = Activation('relu')\n",
            "model.add(convout3)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "convout4 = Activation('relu')\n",
            "model.add(convout4)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "model.add(Flatten())\n",
            "model.add(Dense(680))\n",
            "model.add(Activation('relu'))\n",
            "model.add(Dense(128))\n",
            "model.add(Activation('relu'))\n",
            "model.add(Dropout(0.5))\n",
            "model.add(Dense(5))\n",
            "model.add(Activation('softmax'))\n",
            "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
            "\n",
            "from keras import models\n",
            "from keras import layers\n",
            "from keras import optimizers\n",
            "\n",
            "model = models.Sequential()\n",
            "model.add(layers.Dense(256, activation='relu', input_dim=7 * 7 * 512))\n",
            "model.add(layers.Dropout(0.5))\n",
            "model.add(layers.Dense(1, activation='sigmoid'))\n",
            "model.compile(optimizer=optimizers.RMSprop(lr=2e-4),\n",
            "              loss='binary_crossentropy',\n",
            "              metrics=['acc'])\n",
            "nb_filters = 30\n",
            "# size of pooling area for max pooling\n",
            "nb_pool = 2\n",
            "# convolution kernel size\n",
            "nb_conv = 4\n",
            "\n",
            "\n",
            "# number of output classes\n",
            "nb_classes = 5\n",
            "# number of epochs to train\n",
            "nb_epoch = 64\n",
            "\n",
            "img_rows, img_cols = 750,750\n",
            "from keras.models import Sequential\n",
            "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
            "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
            "from keras.optimizers import SGD,RMSprop,adam\n",
            "import keras\n",
            "\n",
            "adam = keras.optimizers.Adam(lr=3e-03, beta_1=0.9, beta_2=0.9999, epsilon=None, decay=0.00001, amsgrad=False)\n",
            "\n",
            "model = Sequential()\n",
            "\n",
            "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
            "                        border_mode='valid',\n",
            "                        input_shape=(img_cols, img_rows, 3)))\n",
            "convout1 = Activation('relu')\n",
            "model.add(convout1)\n",
            "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
            "model.add(Dropout(0.5))\n",
            "convout2 = Activation('relu')\n",
            "model.add(convout2)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+1, nb_pool+1)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "convout3 = Activation('relu')\n",
            "model.add(convout3)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "convout4 = Activation('relu')\n",
            "model.add(convout4)\n",
            "model.add(Convolution2D(nb_filters, nb_conv-1, nb_conv-1))\n",
            "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
            "model.add(Dropout(0.5))\n",
            "\n",
            "model.add(Flatten())\n",
            "model.add(Dense(680))\n",
            "model.add(Activation('relu'))\n",
            "model.add(Dense(128))\n",
            "model.add(Activation('relu'))\n",
            "model.add(Dropout(0.5))\n",
            "model.add(Dense(5))\n",
            "model.add(Activation('softmax'))\n",
            "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
            "hist = model.fit_generator(train_generator, steps_per_epoch=64, epochs=1000, validation_data=val_generator, validation_steps=50)\n",
            "history = model.fit_generator(train_generator, steps_per_epoch=64, epochs=1000, validation_data=val_generator, validation_steps=50)\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# summarize history for accuracy\n",
            "plt.plot(history.history['acc'])\n",
            "plt.plot(history.history['val_acc'])\n",
            "plt.title('model accuracy')\n",
            "plt.ylabel('accuracy')\n",
            "plt.xlabel('epoch')\n",
            "plt.legend(['train', 'test'], loc='upper left')\n",
            "plt.show()\n",
            "# summarize history for loss\n",
            "plt.plot(history.history['loss'])\n",
            "plt.plot(history.history['val_loss'])\n",
            "plt.title('model loss')\n",
            "plt.ylabel('loss')\n",
            "plt.xlabel('epoch')\n",
            "plt.legend(['train', 'test'], loc='upper left')\n",
            "plt.show()\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# summarize history for accuracy\n",
            "plt.plot(history.history['acc'])\n",
            "plt.plot(history.history['val_acc'])\n",
            "plt.title('model accuracy')\n",
            "plt.ylabel('accuracy')\n",
            "plt.xlabel('epoch')\n",
            "plt.legend(['train', 'test'], loc='upper left')\n",
            "plt.show()\n",
            "# summarize history for loss\n",
            "plt.plot(history.history['loss'])\n",
            "plt.plot(history.history['val_loss'])\n",
            "plt.title('model loss')\n",
            "plt.ylabel('loss')\n",
            "plt.xlabel('epoch')\n",
            "plt.legend(['train', 'test'], loc='upper left')\n",
            "plt.show()\n",
            "history\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2fjg2MqL0jG9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}